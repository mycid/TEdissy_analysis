---
title: "Protein Content Analysis using the Lowry Method"
output: html_document
params:
  plot_dir:    "output_prot/plots"
  data_dir:    "output_prot/export_data"
  report_dir:  "output_prot/reports"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Load script and directories
```{r}
# Source script from top-level project folder
source("../process_plate_run.R")
#— 1. pull from params (or use defaults)
plot_dir   <- params$plot_dir   %||% "output_prot/plots"
data_dir   <- params$data_dir   %||% "output_prot/export_data"
report_dir <- params$report_dir %||% "output_prot/reports"

#— 2. create all dirs
walk(
  c(plot = plot_dir, data = data_dir, reports = report_dir),
  ~ if (!dir_exists(.x)) dir_create(.x, recurse = TRUE)
)

#— 3. register plot_dir with knitr
opts_chunk$set(fig.path = paste0(plot_dir, "/"))
#
```

## Load input data
```{r load-excel-files, warning=FALSE}
# 1. Define the folder containing all Excel inputs
input_folder <- "Input_prot"

# 2. Find all .xlsx files (full paths), excluding temp files that start with "~$"
excel_files <- list.files(
  path = input_folder, 
  pattern = "\\.xlsx?$", 
  full.names = TRUE
)
excel_files <- excel_files[!grepl("^~\\$", basename(excel_files))]

# 3. Loop over each file
for (file in excel_files) {
  # 3a. Create a clean object name (strip out folder & extension)
  name <- tools::file_path_sans_ext(basename(file))
  
  # 3b. Determine which sheet to read (second if possible, otherwise first)
  sheet_names   <- excel_sheets(file)
  sheet_to_read <- if (length(sheet_names) >= 2) sheet_names[2] else sheet_names[1]
  
  # 3c. Read the chosen sheet, suppressing verbose messages
  data <- suppressMessages(read_excel(file, sheet = sheet_to_read))
  
  # 3d. Assign the data.frame to the global environment under "name"
  assign(name, data, envir = .GlobalEnv)
  
  # 3e. Print a message to confirm successful load
  message("Loaded: ", name, " (sheet = '", sheet_to_read, "')")
}
```

### Tidy photospectrometer input data into dataframes and correct blanks
```{r tidy-processing}
# 1. Define which wells were used as blanks in each run
blanks1 <- c("A01", "A02", "A03")
blanks2 <- c("H11", "H12")
#
# 2. Build named lists of raw datasets and their corresponding blank vectors
listprot    <- list(pr1 = pr1, pr2 = pr2)
#
listBlanks <- list(blanks1, blanks2)
#
# 3. Run the wrapper: it calls tidy_and_correct() on each dataset
tidy_all(listprot, listBlanks)

```
## STEP 5: JOIN THE DATA WITH ITS SAMPLE WEIGHTS SPREADSHEET

Description of `joindf_by_id` Function

The `joindf_by_id` function takes two data frames (`df1` and `df2`) and merges them by matching unique identifiers related to samples, specifically using either a `Cell_ID` column or a `plate well` column.\
**Key steps and features:** - **Column Cleaning:** Trims whitespace from column names in both data frames to avoid join errors caused by accidental spaces.
- **Key Column Verification:** Checks that at least one data frame contains a `Cell_ID` column and the other contains a `plate well` column—these serve as the join keys.
- **Role Assignment:** Depending on which data frame contains `Cell_ID`, that data frame is assigned as the base (`df_cell`), and the other becomes the joining data (`df_plate`).
- **Rename Join Keys:** Renames both join columns to a common key name (`join_id`) to facilitate a straightforward left join.
- **Perform Join:** Conducts a left join, keeping all rows from the base data frame and adding matching data from the other.
- **Identify Unmatched Rows:** Any rows in the larger data frame without matches are saved separately for troubleshooting.
- **Output Files:**\
- Saves the merged data frame as a CSV named according to the provided `output_name`.\
- Writes unmatched rows into a separate CSV file.\
- **Global Environment Assignment:** Assigns the merged data frame into the global R environment under the same name as the output file (minus the `.csv` extension).
- **Reporting:** Prints messages listing any unmatched identifiers and returns a summary report containing counts of matched/unmatched rows and file paths of saved CSVs.

```{r join-weights, warning=FALSE}
# 1. Create output subdirectory
# 1. Create subdirectory for joined weights inside data_dir
joined_weights_dir <- file.path(data_dir, "joined_weights_prot")
if (!dir.exists(joined_weights_dir)) dir.create(joined_weights_dir, recursive = TRUE)

# 1. Build weight and PE data frame lists
list_weights <- list(
  pr1_weights,
  pr2_weights
)

pr_list <- list(
  pr1 = pr1_tidy, 
  pr2 = pr2_tidy
)

# 2. Extract names to use in assign_name and filenames
df_names <- names(pr_list)

# 3. Join + save using joindf_by_id
mapply(
  function(df1, df2, name) {
    assign_name <- paste0(name, "_weights_joined")
    csv_path    <- file.path(joined_weights_dir, paste0(assign_name, ".csv"))
    
    joindf_by_id(
      df1         = df1,
      df2         = df2,
      key_df1     = "Cell_ID",
      key_df2     = "plate well",
      assign_name = assign_name,
      save_csv_path = csv_path
    )
  },
  df1 = pr_list,
  df2 = list_weights,
  name = df_names,
  SIMPLIFY = FALSE
)
```

## Create Standard Curve from Lowry Assay


```{r standard-curve, message=FALSE, warning=FALSE}

# Example data: Replace this with your actual data
# You can also use `read.csv("your_data.csv")` if loading from a file

# Fit linear model
model <- lm(X600_cor ~ concentration, data = calibration_prot)

# Summary of the model (for table output, if needed)
summary(model)

# Plot
prot_curve_plot <- ggplot(calibration_prot, aes(x = concentration, y = X600_cor)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(
    title = "Protein Standard Curve (Lowry Method)",
    x = "Protein Concentration (mg/mL)",
    y = "Absorbance (600 nm)"
  ) +
  annotate(
    "text",
    x = max(calibration_prot$concentration) * 0.5, 
    y = max(calibration_prot$X600_cor) * 0.9,
    label = paste0("y = ", round(coef(model)[2], 4), "x + ", round(coef(model)[1], 4),
                   "\nR² = ", round(summary(model)$r.squared, 4)),
    size = 4, hjust = 0
  ) +
  theme_minimal()

# Save using save_object()
save_object(prot_curve_plot,
            filename  = "protein_standard_curve",
            directory = "plots",
            width     = 6,
            height    = 5,
            dpi       = 300)
print(prot_curve_plot)
```
## Calculate protein concentration with standard curve regression
```{r}
# Use the regression model to predict concentration from absorbance
export_dir <- "output_prot/export_data"
plot_dir <- file.path("output_prot", "plots")
dir.create(export_dir, recursive = TRUE, showWarnings = FALSE)
dir.create(plot_dir, recursive = TRUE, showWarnings = FALSE)

# ---- Step 1: Calibration
intercept <- coef(model)[1]
slope     <- coef(model)[2]

# ---- Step 2: Harmonize inputs
common_cols <- intersect(names(pr2_weights_joined), names(pr1_weights_joined))
pr1_weights_joined <- pr1_weights_joined %>% mutate(weights = as.numeric(weights), date = parse_date_time(date, orders = c("ymd", "dmy", "mdy")))
pr2_weights_joined <- pr2_weights_joined %>% mutate(weights = as.numeric(weights), date = parse_date_time(date, orders = c("ymd", "dmy", "mdy")))

# ---- Step 3: Combine datasets and calculate concentrations
pr_combined <- bind_rows(pr2_weights_joined[common_cols], pr1_weights_joined[common_cols])
pr_combined$con_mg_per_ml <- (pr_combined$X600 - intercept) / slope
pr_combined$Protein_mg_total <- pr_combined$con_mg_per_ml * 0.5
pr_combined$Protein_mg_per_g <- (pr_combined$Protein_mg_total / pr_combined$weights) * 1000

# ---- Step 4: Filter and factor runs
pr_combined <- pr_combined %>%
  filter(is.finite(Protein_mg_per_g), !is.na(Protein_mg_per_g)) %>%
  mutate(run = as.factor(match(as.Date(date), unique(as.Date(date)))))

# Save combined data
write_csv(pr_combined, file.path(export_dir, "pr_combined.csv"))

# ---- Step 5: Statistical tests
t_test_result <- t.test(Protein_mg_per_g ~ run, data = pr_combined)
wilcox_result <- wilcox.test(Protein_mg_per_g ~ run, data = pr_combined)

# Save test summaries
capture.output(t_test_result,   file = file.path(export_dir, "t_test_run_comparison.txt"))
capture.output(wilcox_result,  file = file.path(export_dir, "wilcox_test_run_comparison.txt"))

# ---- Step 6: Plot protein content by run
protein_run_plot <- ggplot(pr_combined, aes(x = run, y = Protein_mg_per_g, fill = run)) +
  geom_boxplot(outlier.shape = NA, width = 0.6) +
  geom_jitter(width = 0.1, alpha = 0.5, color = "black") +
  labs(title = "Protein Content by Run", x = "Run", y = "Protein (mg/g)") +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))

save_object(
  object    = protein_run_plot,
  filename  = "protein_content_by_run",
  directory = "plots",
  subdir    = "replicate_analysis/protein"
)

# ---- Step 7: Outlier detection
df_runs12 <- pr_combined %>% filter(run %in% c("1", "2"))
iqr_vals <- IQR(df_runs12$Protein_mg_per_g, na.rm = TRUE)
q1 <- quantile(df_runs12$Protein_mg_per_g, 0.25, na.rm = TRUE)
q3 <- quantile(df_runs12$Protein_mg_per_g, 0.75, na.rm = TRUE)
lower_bound <- q1 - 1.5 * iqr_vals
upper_bound <- q3 + 1.5 * iqr_vals

pr_combined <- pr_combined %>%
  mutate(outlier_flag = ifelse(
    Protein_mg_per_g < lower_bound | Protein_mg_per_g > upper_bound,
    "outlier", "normal"
  ))

# Save outlier-flagged data
write_csv(pr_combined, file.path(export_dir, "pr_combined_with_outliers.csv"))

pr_combined_clean <- pr_combined %>% filter(outlier_flag == "normal")
write_csv(pr_combined_clean, file.path(export_dir, "pr_combined_clean.csv"))

# ---- Step 8: Replicate analysis
analyze_replicates(
  data          = pr_combined_clean,
  id_col        = "ID",
  join_col      = "join_id",
  weight_col    = "weights",
  date_col      = "date",
  output_prefix = "pr_rep",
  choose_best_3 = TRUE,
  dir           = export_dir
)

# ---- Step 9: Replicate summary and plot
protein_summary <- read_csv(file.path(export_dir, "pr_rep_summary.csv"))

protein_var     <- "Protein_mg_per_g"
se_col_name     <- paste0(protein_var, "_se")
mean_col_name   <- paste0(protein_var, "_mean")

output_prefix <- file.path(plot_dir, "replicate_analysis", paste0(protein_var, "_replicate_analysis"))
dir.create(dirname(output_prefix), recursive = TRUE, showWarnings = FALSE)

protein_plot <- graph_replicates_custom_error(
  data          = protein_summary,
  id_col        = "ID",
  value_col     = mean_col_name,
  se_col        = se_col_name,
  output_prefix = output_prefix
)

save_object(
  object    = protein_plot,
  filename  = paste0(protein_var, "_replicate_plot"),
  directory = "plots",
  format    = "html",
  subdir    = "replicate_analysis/protein"
)

# ---- Step 10: Summary stats
summary_stats <- protein_summary %>%
  summarise(
    total_rows       = n(),
    high_cv_count    = sum(Protein_mg_per_g_cv > 0.2, na.rm = TRUE),
    average_cv       = mean(Protein_mg_per_g_cv, na.rm = TRUE),
    high_cv_percent  = mean(Protein_mg_per_g_cv > 0.2, na.rm = TRUE) * 100
  )

write_csv(summary_stats, file.path(export_dir, "protein_summary_stats.csv"))

# Also print to console (optional)
print(summary_stats)

```
## Analize protein content by sample
```{r}
# 1. Merge enhanced replicate summary with metadata by column "ID"
#    This will save "PErep_final.csv" and assign the merged data frame to `PErep_final`.
# 1. Define export folder and create it if needed
final_export_dir <- file.path("output_prot", "export data", "Samples Analysis Final")
dir.create(final_export_dir, recursive = TRUE, showWarnings = FALSE)

#

# 2. Join PErep_enhanced with Sample data
joindf_by_id(
  df1          = protein_summary,
  df2          = `Sample data`,
  save_csv_path  = file.path(final_export_dir, "pr_rep_final.csv"),
  assign_name  = "pr_rep_final",
  key_df1      = "ID",
  key_df2      = "ID"
)

# 4. Define output directory for replicate analysis plots
rep_plot_dir <- file.path("output_prot", "plots", "replicate_analysis")
dir.create(rep_plot_dir, recursive = TRUE, showWarnings = FALSE)

# 5. Generate histogram with error bars for PE_mg_per_g_sample_mean
graph_replicates_custom_error(
  data          = pr_rep_final,
  id_col        = "Location",
  value_col     = "Protein_mg_per_g_mean",
  se_col        = "Protein_mg_per_g_se",
  output_prefix = file.path(rep_plot_dir, "protein_rep_analy_bylocation")
)

pr_location <- pr_rep_final %>%
  filter(!Location %in% c("Lima Market Freeze Dry", "Ilo Freeze Dry", "Ilo oven dry", "Ilo Fresh", "Lima Market Fresh"))

pr_location_cham <- pr_rep_final %>%
  filter(!variety %in% c("F.Glom"))
# 6. Run group comparisons and print outputs

###################################################Location
compare_groups(
  data         = pr_location_cham,
  response_var = "Protein_mg_per_g_mean",
  group_var    = "Location",
  subfolder_name = "pr_Location_cham"
)

################################################Life_S
compare_groups(
  data         = pr_location_cham,
  response_var = "Protein_mg_per_g_mean",
  group_var    = "Life_S",
  subfolder_name = "pr_Life_S_cham"
)

###########################################Variety
pr_paracas_marcona <- pr_rep_final %>%
  filter(Location %in% c("Mendieta", "7H", "Caro Caido"))

compare_groups(
  data         = pr_paracas_marcona,
  response_var = "Protein_mg_per_g_mean",
  group_var    = "variety",
  subfolder_name = "pr_variety"
)

#################################Gam Cham

pr_gamtetra <- pr_location %>%
  filter(Life_S %in% c("Gam/Tetra", "Gam", "Tetra"))

compare_groups(
  data         = pr_gamtetra,
  response_var = "Protein_mg_per_g_mean",
  group_var    = "Location",
  subfolder_name = "pr_gamtetra_location"
)

```