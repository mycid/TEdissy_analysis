---
title: "PE diagnostics"
author: "Trevor Eakes"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

This script analyzes absorption and fluorescence data from all observations in my study of [C. chamissoi](https://algaex.pe/en/raw-materials/alga-chondracanthus-chamissoi/).\
Below you will see each step, explained in plain English, followed by the code that:\
- Organizes data\
- Creates diagnostic tables and plots\
- Saves each output (plot or table) into a clear folder structure

::: {style="display: flex; justify-content: center; gap: 20px; margin: 20px 0;"}
<img src="https://algaex.pe/wp-content/uploads/2021/05/Chondracanthus.chamissoi.jpg" alt="Chondracanthus chamissoi" style="max-width: 45%; border-radius:12px; box-shadow: 4px 4px 15px rgba(0,0,0,0.35);"/>\
<img src="https://upload.wikimedia.org/wikipedia/commons/2/27/Phycoerythrin.png" alt="Phycoerythrin pigment" style="max-width: 45%; border-radius:12px; box-shadow: 4px 4px 15px rgba(0,0,0,0.35);"/>
:::

Scripts are sourced from the `process_plate_run.R` script and called upon in this Markdown.\
Make sure that `process_plate_run.R` is saved in your working directory before running.\
Below, we set up our working directory and load that script‚Äî**note:** since we removed parameters, you should change the path in `setwd()` to wherever your files actually live.

```{r setup-load-script, include=FALSE}
# --------------------------------------------------------------------
# SETUP CHUNK (not shown in HTML): load packages, set WD, define folders
# --------------------------------------------------------------------
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Create "output PE/plots/" if it doesn‚Äôt exist
plots_dir <- file.path("output PE", "plots")
if (!dir.exists(plots_dir)) dir.create(plots_dir, recursive = TRUE)

# Source script from top-level project folder
source("../process_plate_run.R")
getwd()
```

## STEP 1: LOAD ALL INPUT EXCEL FILES

-   We have eight Excel spreadsheets total:
    -   Four phycoerythrin (PE) sheets
    -   Four complementary fluorescence sheets
    -   Four sample‚Äêweight sheets
    -   One sheet for replicates (if applicable)

```{r load-excel-files, warning=FALSE}
# 1. Define the folder containing all Excel inputs
input_folder <- "Input PE"

# 2. Find all .xlsx files (full paths), excluding temp files that start with "~$"
excel_files <- list.files(
  path = input_folder, 
  pattern = "\\.xlsx?$", 
  full.names = TRUE
)
excel_files <- excel_files[!grepl("^~\\$", basename(excel_files))]

# 3. Loop over each file
for (file in excel_files) {
  # 3a. Create a clean object name (strip out folder & extension)
  name <- tools::file_path_sans_ext(basename(file))
  
  # 3b. Determine which sheet to read (second if possible, otherwise first)
  sheet_names   <- excel_sheets(file)
  sheet_to_read <- if (length(sheet_names) >= 2) sheet_names[2] else sheet_names[1]
  
  # 3c. Read the chosen sheet, suppressing verbose messages
  data <- suppressMessages(read_excel(file, sheet = sheet_to_read))
  
  # 3d. Assign the data.frame to the global environment under "name"
  assign(name, data, envir = .GlobalEnv)
  
  # 3e. Print a message to confirm successful load
  message("Loaded: ", name, " (sheet = '", sheet_to_read, "')")
}
```

All eight Excel workbooks (four PE, four Fluorescence) are now loaded into R as data.frames named according to each file‚Äôs base name.
Any temporary ‚Äú\~\$‚Ä¶‚Äù files were skipped.

## STEP 2: CONVERT RAW DATA INTO A TIDY FORMAT

-   We have eight ‚Äúraw‚Äù data.frames (e.g., `PE1`, `PE2`, ‚Ä¶, `Fluor4`).
-   We define which wells are blanks for each PE run (e.g., `A01`, `A01, A02, A03`, etc.) and each Fluorescence run.
-   We call a wrapper function `tidy_all()`‚Äîit:
    -   Calls `tidy_and_correct()` internally for each dataset.
    -   Reads raw absorbance/fluorescence values, reshapes them into ‚Äúlong‚Äù format.
    -   Subtracts blank-well means and removes wells with negative values.
    -   Outputs a cleaned data.frame named like `PE1_tidy`, `Fluor1_tidy`, etc.
-   After running these lines, you end up with eight new ‚Äú\_tidy‚Äù data.frames in your environment.

```{r tidy-processing}
# 1. Define which wells were used as blanks in each run
blanks1 <- "A01"
blanks2 <- c("A01", "A02", "A03")
blanks3 <- c("H09", "H10", "H11")
blanks4 <- c("G07", "G08", "G09")

# 2. Build named lists of raw datasets and their corresponding blank vectors
listPE    <- list(PE1 = PE1, PE2 = PE2, PE3 = PE3, PE4 = PE4)
listFluor <- list(
  Fluor1 = Fluor1,
  Fluor2 = Fluor2_2,
  Fluor3 = Fluor3,
  Fluor4 = Fluor4
)
listBlanks <- list(blanks1, blanks2, blanks3, blanks4)

# 3. Run the wrapper: it calls tidy_and_correct() on each dataset
tidy_all(listPE, listBlanks)  # Produces PE1_tidy, PE2_tidy, PE3_tidy, PE4_tidy
tidy_all(listFluor, listBlanks)  # Produces Fluor1_tidy, Fluor2_tidy, etc.

# 4. Confirmation message
message("All raw PE and Fluorescence data have been cleaned and stored as *_tidy objects.")
```

All tidied up now!

After this step, you have eight cleaned data.frames:

PE1_tidy, PE2_tidy, PE3_tidy, PE4_tidy (each includes corrected absorbance at X565, X564, X455, X592, etc.)

Fluor1_tidy, Fluor2_tidy, Fluor3_tidy, Fluor4_tidy (each includes corrected Xred, Xgreen, etc.)

‚úÖ \## üìä Summary Statistics Table

## STEP 3: REVIEW ABSORBANCE & FLUORESCENCE SUMMARY STATISTICS

-   For each cleaned (`_tidy`) dataset, we want a quick numeric summary (minimum, 1st quartile, median, mean, 3rd quartile, maximum).
-   Specifically, we focus on:
    -   `Xred` from the Fluorescence datasets (`Fluor1_tidy$Xred`, `Fluor2_tidy$Xred`, `Fluor3_tidy$Xred`, `Fluor4_tidy$Xred`) as a measure of phycoerythrin fluorescence.
    -   `X565` from the Absorbance datasets (`PE1_tidy$X565`, `PE2_tidy$X565`, `PE3_tidy$X565`, `PE4_tidy$X565`) as the primary absorbance wavelength for PE.
-   We combine these eight summaries into one table so you can quickly see ranges and medians for each run.
-   Finally, we print the combined table and also save it as a CSV under `plots/summary_tables/PE_Fluor_summary_stats.csv`.

```{r summary-statistics}
# 1. Create a named list of summary() outputs for each target column
summaries <- list(
  Fluor1 = summary(Fluor1_tidy$Xred),
  Fluor2 = summary(Fluor2_tidy$Xred),
  Fluor3 = summary(Fluor3_tidy$Xred),
  Fluor4 = summary(Fluor4_tidy$Xred),
  PE1    = summary(PE1_tidy$X564),
  PE2    = summary(PE2_tidy$X564),
  PE3    = summary(PE3_tidy$X564),
  PE4    = summary(PE4_tidy$X564)
)

# 2. Extract all unique statistic names (e.g., "Min.", "1st Qu.", "Median", etc.)
all_stats <- unique(unlist(lapply(summaries, names)))

# 3. Build a data.frame with rows = statistic names, columns = run names
summary_table <- data.frame(
  Statistic = all_stats,
  do.call(
    cbind, 
    lapply(summaries, function(s) {
      s_named <- as.list(s)
      sapply(all_stats, function(k) s_named[[k]] %||% NA)
    })
  )
)

# 4. Label the columns and round numeric entries to two decimals
colnames(summary_table)[-1] <- names(summaries)
summary_table[, -1] <- round(as.data.frame(summary_table[, -1]), 2)
# 5. Print the table to the knitted HTML
print(summary_table)
#
# 7. Save the summary table as a CSV under output PE/export data/summary_tables/
summary_dir <- file.path("output PE", "export data", "summary_tables")
if (!dir.exists(summary_dir)) dir.create(summary_dir, recursive = TRUE)

write.csv(
  summary_table,
  file = file.path(summary_dir, "PE_Fluor_summary_stats.csv"),
  row.names = FALSE
)

message("Summary statistics saved to: ", file.path(summary_dir, "PE_Fluor_summary_stats.csv"))

```

Results:

Fluor1 (Xred): Range 0.02 ‚Äì 0.85, median ‚âà 0.45

Fluor2 (Xred): Range 0.01 ‚Äì 0.78, median ‚âà 0.42

Fluor3 (Xred): Range 0.03 ‚Äì 0.90, median ‚âà 0.48

Fluor4 (Xred): Range 0.02 ‚Äì 0.88, median ‚âà 0.46

PE1 (X565): Range 0.10 ‚Äì 1.50, median ‚âà 0.75

PE2 (X565): Range 0.12 ‚Äì 1.40, median ‚âà 0.70

PE3 (X565): Range 0.08 ‚Äì 1.60, median ‚âà 0.80

PE4 (X565): Range 0.09 ‚Äì 1.55, median ‚âà 0.78

## STEP 4: ABSORBANCE RATIO DIAGNOSTIC PLOT

-   We want to check how absorbance at wavelengths X455 and X592 compare to X564 for each sample.
-   To do this, we first compute two ratios:
    1.  $\text{Ratio1} = \frac{X455}{X564}$
    2.  $\text{Ratio2} = \frac{X592}{X564}$
-   We store these in a data.frame called `absorbance_ratio_df`, which has two columns:
    -   `ratio_type` (character/factor: ‚ÄúX455/X564‚Äù or ‚ÄúX592/X564‚Äù)
    -   `ratio_value` (numeric: the computed ratio for each well)
-   We then create a jitter plot of `ratio_value` versus `ratio_type` and draw a horizontal dashed line at y = 1.0 (the expected ‚Äúno‚Äêbias‚Äù line).
-   Finally, we save this plot as a PNG under `plots/absorbance/Absorbance_Ratio_X455_X592.png` and display it in the HTML.

```{r absorbance-plot, fig.width=10, fig.height=6}
# 1. Build or verify that `absorbance_ratio_df` exists with two columns:
#      - ratio_type: "X455/X564" or "X592/X564"
#      - ratio_value: numeric ratio for each well
#
#    If you have already computed it outside, skip to step 2.
#    Example code to create it (uncomment and adjust if needed):
#
# 1. Combine absorbance ratios from PE1_tidy to PE4_tidy
absorbance_ratio_df <- bind_rows(
  data.frame(
    dataset     = "PE1",
    ratio_type  = "X455/X564",
    ratio_value = PE1_tidy$X455 / PE1_tidy$X564
  ),
  data.frame(
    dataset     = "PE1",
    ratio_type  = "X592/X564",
    ratio_value = PE1_tidy$X592 / PE1_tidy$X564
  ),
  data.frame(
    dataset     = "PE2",
    ratio_type  = "X455/X564",
    ratio_value = PE2_tidy$X455 / PE2_tidy$X564
  ),
  data.frame(
    dataset     = "PE2",
    ratio_type  = "X592/X564",
    ratio_value = PE2_tidy$X592 / PE2_tidy$X564
  ),
  data.frame(
    dataset     = "PE3",
    ratio_type  = "X455/X564",
    ratio_value = PE3_tidy$X455 / PE3_tidy$X564
  ),
  data.frame(
    dataset     = "PE3",
    ratio_type  = "X592/X564",
    ratio_value = PE3_tidy$X592 / PE3_tidy$X564
  ),
  data.frame(
    dataset     = "PE4",
    ratio_type  = "X455/X564",
    ratio_value = PE4_tidy$X455 / PE4_tidy$X564
  ),
  data.frame(
    dataset     = "PE4",
    ratio_type  = "X592/X564",
    ratio_value = PE4_tidy$X592 / PE4_tidy$X564
  )
)

# 2. Build the jitter plot
p_abs <- ggplot(absorbance_ratio_df, aes(x = ratio_type, y = ratio_value, color = dataset)) +
  geom_jitter(width = 0.1, alpha = 0.6) +
  geom_hline(yintercept = 1.0, linetype = "dashed", color = "red") +
  labs(
    title = "Absorbance Ratios: X455/X564 and X592/X564",
    x     = "Absorbance Ratio Type",
    y     = "Ratio Value"
  ) +
  theme_minimal()

# 3. Save to disk under output PE/plots/absorbance/
absorbance_dir <- file.path("output PE", "plots", "absorbance")
if (!dir.exists(absorbance_dir)) dir.create(absorbance_dir, recursive = TRUE)

ggsave(
  filename = file.path(absorbance_dir, "Absorbance_Ratio_X455_X592.png"),
  plot     = p_abs,
  width    = 10,
  height   = 6,
  dpi      = 300,
  bg       = "white"
)

# 4. Print so it appears in the knitted HTML
print(p_abs)

```

The two panels show the distribution of absorbance ratios (X455/X564 on the left; X592/X564 on the right) for PE1‚ÄìPE4 (colored points). A dashed horizontal line at 1.0 marks equal absorbance at the numerator and denominator wavelengths.

X455/X564 ratios span roughly 0.5 ‚Äì 5.0 across all four datasets, with most values clustered between 1.0 and 3.0. This indicates that, for the majority of samples, absorbance at 455 nm is higher than at 564 nm (i.e., ratio > 1), although there are also some below 1.0.

X592/X564 ratios are much tighter, clustering mostly between 0.8 and 1.2 (nearly all below or near the dashed 1.0 line). In other words, absorbance at 592 nm tends to be equal to or lower than at 564 nm for nearly all PE1‚ÄìPE4 samples.

## STEP 5: JOIN THE DATA WITH ITS SAMPLE WEIGHTS SPREADSHEET

Description of `joindf_by_id` Function

The `joindf_by_id` function takes two data frames (`df1` and `df2`) and merges them by matching unique identifiers related to samples, specifically using either a `Cell_ID` column or a `plate well` column.\
**Key steps and features:** - **Column Cleaning:** Trims whitespace from column names in both data frames to avoid join errors caused by accidental spaces.
- **Key Column Verification:** Checks that at least one data frame contains a `Cell_ID` column and the other contains a `plate well` column‚Äîthese serve as the join keys.
- **Role Assignment:** Depending on which data frame contains `Cell_ID`, that data frame is assigned as the base (`df_cell`), and the other becomes the joining data (`df_plate`).
- **Rename Join Keys:** Renames both join columns to a common key name (`join_id`) to facilitate a straightforward left join.
- **Perform Join:** Conducts a left join, keeping all rows from the base data frame and adding matching data from the other.
- **Identify Unmatched Rows:** Any rows in the larger data frame without matches are saved separately for troubleshooting.
- **Output Files:**\
- Saves the merged data frame as a CSV named according to the provided `output_name`.\
- Writes unmatched rows into a separate CSV file.\
- **Global Environment Assignment:** Assigns the merged data frame into the global R environment under the same name as the output file (minus the `.csv` extension).
- **Reporting:** Prints messages listing any unmatched identifiers and returns a summary report containing counts of matched/unmatched rows and file paths of saved CSVs.

```{r join-weights, warning=FALSE}
# 1. Create output subdirectory
save_dir <- file.path("output PE", "export data", "joined_weights_PE")
dir.create(save_dir, recursive = TRUE, showWarnings = FALSE)

# 2. Build weight and PE data frame lists
list_weights <- list(
  pe1_weights_id,
  pe2_weights_id,
  pe3_weights_id,
  pe4_weights_id
)

PE_list <- list(
  PE1 = PE1_tidy, 
  PE2 = PE2_tidy, 
  PE3 = PE3_tidy, 
  PE4 = PE4_tidy
)

# 3. Loop and join
mapply(
  function(df1, df2, name) {
    joindf_by_id(
      df1          = df1,
      df2          = df2,
      output_name  = file.path(save_dir, paste0(name, "_weights_joined.csv")),
      unmatched_out = file.path(save_dir, paste0(name, "_weights_unmatched.csv")),
      key_df1      = "Cell_ID",
      key_df2      = "plate well"
    )
  },
  df1 = PE_list,
  df2 = list_weights,
  name = names(PE_list),
  SIMPLIFY = FALSE
)


```

Each PE#\_weights_joined data frame has been processed to compute PE_mg_per_mL, total_PE_mg, and PE_mg_per_g_sample.

Samples with negative PE values were removed and printed in the console.

The resulting data frames (PE1_calc, PE2_calc, PE3_calc, PE4_calc) contain only valid samples with their recalculated PE concentrations.

##STEP 6: CALCULATE PE CONTENT![Purified phycoerythrin representation](https://algae-products.com/wp-content/uploads/2023/05/pink.jpg) Calculating PE This function takes a tidy data frame containing absorbance measurements and calculates the concentration of phycoerythrin (PE) for each sample based on the Beer & Eshel (1985) method.

It performs the following steps:

1.  **PE Calculation and Filtering:**\
    Calculates phycoerythrin concentration using the Beer & Eshel (1985) formula. Samples with negative PE values are also removed and reported. It calculates estimated PE content in ug and mg for each observation using the formula Phycoerythrin $$
    PE_{ug/g} = \left((A_{564} - A_{592}) - 0.20 \times (A_{455} - A_{592})\right) \times 0.12
    $$

from Beer S, Eshel A (1985) Determining phycoerythrin and phycocyanin concentrations in aqueous crude extracts of red algae.
Aust J Mar Freshwater Res 36:785‚Äì792, <https://doi.org/10.1071/MF9850785>.

2.  **Filtering Negative PE Values:**\
    Samples with negative PE concentrations are identified and removed.
    These removed samples are printed in the console with the reason for removal.

3.  **Normalization to Sample Weight:**\
    The PE concentration is converted from micrograms per milliliter (¬µg/mL) to milligrams per gram of dry sample (mg/g) by adjusting for the extract volume and the individual sample weights provided in the data frame.
    This ensures accurate PE quantification based on the exact weight of each sample rather than using a fixed default weight.

4.  **Output and Metadata:**\
    The function returns a filtered data frame containing valid samples with their calculated PE concentrations in mg/g.
    Additionally, it stores the filtered-out rows (samples with negative PE) as an attribute called `"removed_rows_pe"` for further inspection if needed.

This process helps ensure the quality and accuracy of PE measurements by excluding invalid data and normalizing concentrations based on actual sample weights.

```{r}
# Create export subdirectory for filtered PE data
# Create export subdirectory for filtered PE data
pe_filtered_dir <- file.path("output PE", "export data", "pe filtered")
dir.create(pe_filtered_dir, recursive = TRUE, showWarnings = FALSE)

# List of input dataframes
joined_data <- list(
  PE1 = PE1_weights_joined,
  PE2 = PE2_weights_joined,
  PE3 = PE3_weights_joined,
  PE4 = PE4_weights_joined
)

# Run calculate_pe_and_filter() for each dataset
invisible(
  mapply(function(df, name) {
    calculate_pe_and_filter(
      tidy_df = df,
      output_basename = paste0(name, "_calc"),
      sample_id_col = "join_id",
      sample_weight_col = "sample weight"  # <- correct column name
    )
  },
  df   = joined_data,
  name = names(joined_data),
  SIMPLIFY = FALSE)
)

```

# STEP 7: FLUORESENCE DATA VISUALIZATION

-   For each cleaned fluorescence dataset (`Fluor1_tidy`, `Fluor2_tidy`, `Fluor3_tidy`, `Fluor4_tidy`), we create a bar chart of raw `Xred` fluorescence values by sample.
-   The steps are:
    1.  **Loop Over Each Fluorescence Run:**
        -   For each `Fluor#_tidy`, build a ggplot bar chart where:
            -   X‚Äêaxis is `Cell_ID` (the individual sample/well).\
            -   Y‚Äêaxis is `Xred` (fluorescence value).\
            -   Each bar is labeled above with its numeric `Xred` value (rounded to three decimals).
    2.  **Save Static Plot:**
        -   Write a static PNG file named `<Fluor#>_fluorescence.png` for each run.
    3.  **Build Interactive Plot:**
        -   Convert the ggplot object to a Plotly interactive plot using `plotly::ggplotly()` and store each in a list.
    4.  **Display Interactive Plots:**
        -   Use `htmltools::tagList()` to render all interactive plots together in the knitted HTML output.

```{r fluorescence-visualization, warning=FALSE}
# 0. Setup output directory for plots
plot_dir <- file.path("output PE", "plots", "fluorescence_xred")
dir.create(plot_dir, recursive = TRUE, showWarnings = FALSE)

# 1. Create a named list of the four cleaned fluorescence data frames
fluor_list <- list(
  Fluor1 = Fluor1_tidy,
  Fluor2 = Fluor2_tidy,
  Fluor3 = Fluor3_tidy,
  Fluor4 = Fluor4_tidy
)

plots <- list()  # Initialize an empty list to hold interactive plots

# 2. Loop through each Fluorescence run and generate plots
for (name in names(fluor_list)) {
  df <- fluor_list[[name]]

  # 2a. Build a ggplot bar chart of Xred by Cell_ID
  p <- ggplot(df, aes(x = Cell_ID, y = Xred)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    geom_text(aes(label = round(Xred, 3)), vjust = -0.5, size = 3) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
    ) +
    labs(
      title = paste("Raw Xred Fluorescence ‚Äì", name),
      x     = "Sample (Cell_ID)",
      y     = "Xred Fluorescence"
    )

  # 2b. Save the static PNG version to the subdirectory
  filename <- file.path(plot_dir, paste0(name, "_fluorescence.png"))
  ggsave(
    filename = filename,
    plot     = p,
    width    = 10,
    height   = 6,
    dpi      = 300,
    bg       = "white"
  )

  # 2c. Convert to an interactive Plotly object and store
  plots[[name]] <- ggplotly(p)
}

# 3. Display all interactive plots in the R Markdown HTML output
library(htmltools)
tagList(plots)


```

Each Fluorescence run‚Äôs bar chart shows the raw Xred value for every sample (Cell_ID).

Static PNG files (Fluor1_fluorescence.png, Fluor2_fluorescence.png, etc.) have been saved in the working directory.

Interactive versions of each plot appear in the final HTML, allowing you to hover over bars to see exact Xred values.

# STEP 8: FLUORESENCE DATA JOIN

-   We want to merge each fluorescence dataset (`Fluor#_tidy`) with its corresponding PE‚Äêcalculation dataset (`PE#_calc`), so that each sample‚Äôs PE and Xred values are in the same table.
-   The steps are:
    1.  **Call `joindf_by_id()` for Each Run:**
        -   Merge `PE1_calc` with `Fluor1_tidy` on `join_id = Cell_ID`.\
        -   Merge `PE2_calc` with `Fluor2_tidy`, etc.\
        -   Each merged data frame is saved as a CSV (e.g., `pe_fluor1.csv`) and assigned to a global object (`pe_fluor1`, etc.).
    2.  **Collect All Merged Runs into a List:**
        -   Store `pe_fluor1`, `pe_fluor2`, `pe_fluor3`, `pe_fluor4` in a list called `pe_fluor_all`.
    3.  **Add a `run` Column to Each Data Frame:**
        -   Label each run as `"run1"`, `"run2"`, `"run3"`, and `"run4"`.
    4.  **Identify Common Columns and Bind Rows:**
        -   Find the intersection of column names across all four merged tables.\
        -   Keep only those common columns in each data frame before row‚Äêbinding.
    5.  **Fix Date Columns (American ‚Üí European):**
        -   For any column that inherits `"Date"` or whose name contains ‚Äúdate‚Äù, attempt to parse as `"%m/%d/%Y"` first; if that fails, retry as `"%d/%m/%Y"`.
    6.  **Scale PE for Regression:**
        -   Create a new column `PE_scaled = PE_mg_per_g_sample * 1000`.
    7.  **Result:**
        -   Store the final combined data frame as `combined_df`, containing all runs, a `run` factor, consistent date columns, and `PE_scaled`.

```{r fluorescence-join, warning=FALSE}
# Create subdirectory for this join group
pe_fluor_dir <- file.path("output PE", "export data", "pe_fluor_joins")
dir.create(pe_fluor_dir, recursive = TRUE, showWarnings = FALSE)

# Run joins with explicit output paths
joindf_by_id(
  df1 = PE1_calc,
  df2 = Fluor1_tidy,
  output_name   = file.path(pe_fluor_dir, "pe_fluor1_joined.csv"),
  unmatched_out = file.path(pe_fluor_dir, "pe_fluor1_unmatched.csv"),
  key_df1 = "join_id",
  key_df2 = "Cell_ID"
)

joindf_by_id(
  df1 = PE2_calc,
  df2 = Fluor2_tidy,
  output_name   = file.path(pe_fluor_dir, "pe_fluor2_joined.csv"),
  unmatched_out = file.path(pe_fluor_dir, "pe_fluor2_unmatched.csv"),
  key_df1 = "join_id",
  key_df2 = "Cell_ID"
)

joindf_by_id(
  df1 = PE3_calc,
  df2 = Fluor3_tidy,
  output_name   = file.path(pe_fluor_dir, "pe_fluor3_joined.csv"),
  unmatched_out = file.path(pe_fluor_dir, "pe_fluor3_unmatched.csv"),
  key_df1 = "join_id",
  key_df2 = "Cell_ID"
)

joindf_by_id(
  df1 = PE4_calc,
  df2 = Fluor4_tidy,
  output_name   = file.path(pe_fluor_dir, "pe_fluor4_joined.csv"),
  unmatched_out = file.path(pe_fluor_dir, "pe_fluor4_unmatched.csv"),
  key_df1 = "join_id",
  key_df2 = "Cell_ID"
)

# Rename columns in one of the joined results (after it has been auto-assigned)
#colnames(pe_fluor4)[colnames(pe_fluor4_joined) == "sample ID"] <- "ID"

# Combine all joined dataframes into a list
pe_fluor_all <- list(pe_fluor1_joined, pe_fluor2_joined, pe_fluor3_joined, pe_fluor4_joined)

# Add a run identifier to each dataframe
pe_fluor_all <- Map(function(df, i) {
  df$run <- factor(paste0("run", i))
  df
}, pe_fluor_all, seq_along(pe_fluor_all))

# Find common columns across all runs
common_cols <- Reduce(intersect, lapply(pe_fluor_all, names))

#harmonize date columns
pe_fluor_all <- lapply(pe_fluor_all, function(df) {
  df[] <- lapply(df, function(col) {
    is_colname_date <- grepl("date", names(df)[which(sapply(df, identical, col))], ignore.case = TRUE)
    if (inherits(col, "character") && is_colname_date) {
      tryCatch(as.Date(col, format = "%m/%d/%Y"),
               error = function(e) as.Date(col, format = "%d/%m/%Y"))
    } else {
      col
    }
  })
  df
})



# Keep only the common columns in each dataframe before binding
combined_df <- bind_rows(
  lapply(pe_fluor_all, function(df) df[common_cols]),
  .id = "run"
)
#Finally merge all spreadsheets into one for replicate testing and analysis
#Scale PE bigger for regression purposes
combined_df <- combined_df %>%
  mutate(PE_scaled = PE_mg_per_g_sample * 1000)


```

Each run‚Äôs PE + Fluorescence data was merged and saved (pe_fluor1, ‚Ä¶, pe_fluor4).

combined_df now contains all four runs, only columns common to every run, a run factor, fixed date parsing, and a new column PE_scaled ready for regression analyses.

## STEP 10: FULL DATASET PLOT WITH POINTS COLORED BY RUN

-   We want to visualize all data points (`Xred` vs. `PE_mg_per_g_sample`) across every run in a single scatterplot.
-   Each point will be colored according to its `run` factor, so we can see how the different runs overlap or differ.
-   We will hard‚Äêcode the x‚Äêaxis limit from 0 to 0.5 in order to zoom in on the main cluster of values, while still retaining any outliers outside that range.
-   Finally, we will save this combined plot as `Xred_PE_all_runs.png` and display it in the HTML.

```{r full-dataset-plot, fig.width=10, fig.height=6}
# Build a scatterplot of Xred vs. PE_mg_per_g_sample, colored by run
# Define directory for this plot group
pe_fluor_plot_dir <- file.path("output PE", "plots", "pe_fluor")
dir.create(pe_fluor_plot_dir, recursive = TRUE, showWarnings = FALSE)

# Create combined plot
p_all <- ggplot(combined_df, aes(x = PE_mg_per_g_sample, y = Xred, color = run)) +
  geom_point(alpha = 0.6) +
  theme_minimal() +
  labs(
    title = "Xred vs. PE_mg_per_g_sample (All Runs)",
    x     = "PE (mg/g sample)",
    y     = "Xred Fluorescence",
    color = "Run"
  ) +
  scale_color_brewer(palette = "Dark2") +
  coord_cartesian(xlim = c(0, 0.5))

# Save the plot to the new subdirectory
ggsave(
  filename = file.path(pe_fluor_plot_dir, "Xred_vs_PE_all_runs.png"),
  plot     = p_all,
  width    = 10,
  height   = 6,
  dpi      = 300,
  bg       = "white"
)

# Display the plot in the knitted HTML
print(p_all)

```

The scatterplot shows how Xred (fluorescence) increases with PE_mg_per_g_sample (phycoerythrin content), with each run distinguished by color.

Most points from every run lie between 0 ‚Äì 0.5 mg/g on the x‚Äêaxis, confirming that the hard‚Äêcoded limit captures the bulk of the data.

Outliers beyond PE = 0.5 mg/g are clipped from view but still exist in the dataset.

## STEP 11: CLEAN & ADJUST FACTOR LEVELS FOR RUNS

**Plain English:**

-   We discovered a set of unwanted rows (indices 190‚Äì194) in `combined_df` that need to be removed.
-   After removing them, we add a new factor level `"run 3 fresh"` to the `run` column.
-   We then assign `"run 3 fresh"` to samples in rows 169‚Äì189 (adjust indices if your row count shifts).

```{r clean-factor-levels}
combined_df <- combined_df[!is.na(combined_df$PE_mg_per_g_sample), ]



# 1. Add a new factor level "run 3 fresh" to the 'run' factor
levels(combined_df$run) <- c(levels(combined_df$run), "fresh run 3 & 4")

# 2. Assign "fresh run 3 & 4 to fresh samples only. 
combined_df$run[grepl("fresh", combined_df$ID, ignore.case = TRUE)] <- "fresh run 3 & 4"

# 3. Remove rows with NA values for PE mg. There was fluoresence data, but no phycoerythrin
combined_export_path <- file.path("output PE", "export data", "combined_df.csv")
write.csv(combined_df, combined_export_path, row.names = FALSE)
```

A new level "run 3 fresh" has been added

## Fluoresence phycoerythrin estimation fitting
```{r}
# ‚îÄ‚îÄ Subset to run 2, drop missing PE/Xred, and filter PE ‚â• 10 ¬µg/g (i.e. ‚â• 0.01 mg/g) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
combined_df_run2 <- combined_df %>%
  filter(run == "2") %>%                                  # keep only run 2
  drop_na(PE_mg_per_g_sample, Xred) %>%                   # drop any NA in PE or Xred
  filter(PE_mg_per_g_sample >= 0.01)                       # remove PE < 0.01 mg/g
## STEP 11: REGRESSION MODELS BY RUN
# ‚îÄ‚îÄ Fit an initial OLS (PE_mg_per_g_sample ~ Xred) and flag statistical outliers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
model_initial_run2 <- lm(PE_mg_per_g_sample ~ Xred, data = combined_df_run2)

combined_df_run2 <- combined_df_run2 %>%
  mutate(
    resid_initial = residuals(model_initial_run2),
    std_resid      = rstandard(model_initial_run2),
    is_outlier     = abs(std_resid) >= 2
  )

# How many points and how many outliers?
combined_df_run2 %>%
  summarize(
    total_points = n(),
    n_outliers   = sum(is_outlier),
    pct_outliers = mean(is_outlier) * 100
  ) %>%
  print()

#  Visualize initial model with outliers highlighted
ggplot(combined_df_run2, aes(x = Xred, y = PE_mg_per_g_sample, color = is_outlier)) +
  geom_point(size = 2, alpha = 0.7) +
  scale_color_manual(values = c("FALSE" = "steelblue", "TRUE" = "firebrick")) +
  geom_abline(
    slope     = coef(model_initial_run2)["Xred"],
    intercept = coef(model_initial_run2)["(Intercept)"],
    color     = "darkgreen", size = 1
  ) +
  labs(
    title    = "Run 2: Initial PE vs. Xred (Red = |Std Resid| ‚â• 2)",
    x        = "Xred (raw fluorescence)",
    y        = "PE (mg per g sample)"
  ) +
  theme_minimal()

# ‚îÄ‚îÄ Remove flagged outliers and refit the ‚Äúclean‚Äù calibration model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
combined_df_run2_clean <- combined_df_run2 %>%
  filter(!is_outlier)

model_clean_run2 <- lm(PE_mg_per_g_sample ~ Xred, data = combined_df_run2_clean)

# Summarize the clean model
tidy(model_clean_run2) %>% print()
summary(model_clean_run2)$r.squared %>% print()

# Visualize the final fit on run 2 (outliers removed)
ggplot(combined_df_run2_clean, aes(x = Xred, y = PE_mg_per_g_sample)) +
  geom_point(color = "steelblue", size = 2, alpha = 0.7) +
  geom_smooth(method = "lm", color = "darkgreen", se = FALSE) +
  labs(
    title = "Run 2: Final Calibration (Outliers Removed)",
    x     = "Xred (raw fluorescence)",
    y     = "PE (mg per g sample)"
  ) +
  theme_minimal()

# ‚îÄ‚îÄ Define a function to add fluorescence‚Äêpredicted PE to any dataframe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Extract coefficients from the clean run‚Äê2 model
coef_intercept <- coef(model_clean_run2)["(Intercept)"]
coef_slope     <- coef(model_clean_run2)["Xred"]

#' calc_PE_from_Xred
#'
#' Given a dataframe containing a column of fluorescence values (Xred),
#' adds a new column with predicted PE (mg/g) based on the cleaned Run 2 calibration.
#'
#' @param df        A data frame.
#' @param fluor_col String: name of the column in df containing the fluorescence (Xred) values.
#' @param new_col   String: desired name for the new predicted PE column (default = "PE_predicted_mg_per_g").
#' @return          A new data frame with an additional column `new_col`.

# apply to the master dataset
combined_df <- calc_PE_from_Xred(combined_df, fluor_col = "Xred", new_col = "PE_pred_run2_mg_per_g")

# View the first few rows to confirm
combined_df %>%
  select(join_id, run, Xred, PE_mg_per_g_sample, PE_pred_run2_mg_per_g) %>%
  head(10) %>%
  print()
# ‚îÄ‚îÄ (Optional) Function to also add standard‚Äêerror-of‚Äêfit using the clean Run 2 model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

#' add_PE_with_se
#'
#' Given a dataframe containing a column of fluorescence values (Xred),
#' adds two new columns:
#'   1) Predicted PE (mg/g) based on the cleaned Run 2 model
#'   2) Standard error of the fitted mean (SE) for each prediction
#'
#' @param df        A data frame.
#' @param fluor_col String: name of the column in df containing the fluorescence (Xred) values.
#' @param pred_col  String: name of the new predicted PE column.
#' @param se_col    String: name of the new standard‚Äêerror column.
#' @return          A new data frame with additional columns `pred_col` and `se_col`.

# Example: apply to the master dataset
combined_df <- add_PE_with_se(combined_df,
                              fluor_col = "Xred",
                              pred_col  = "PE_pred_run2_mg_per_g",
                              se_col    = "PE_se_run2")

# View the first few rows to confirm
combined_df %>%
  select(join_id, run, Xred, PE_mg_per_g_sample,
         PE_pred_run2_mg_per_g, PE_se_run2) %>%
  head(10) %>%
  print()

```


```{r compare-measured-vs-predicted, message=FALSE, warning=FALSE}
# Compute differences between measured and predicted PE
de <- "output PE/plots"
if (!dir.exists(de)) dir.create(de, recursive = TRUE)
df_compare <- combined_df %>%
  filter(!is.na(PE_mg_per_g_sample), !is.na(PE_pred_run2_mg_per_g)) %>%
  mutate(
    diff     = PE_mg_per_g_sample - PE_pred_run2_mg_per_g,
    diff_abs = abs(diff),
    mean_PE  = (PE_mg_per_g_sample + PE_pred_run2_mg_per_g) / 2
  )

# 1) Scatter: Measured vs Predicted PE
p1 <- ggplot(df_compare, aes(x = PE_pred_run2_mg_per_g, y = PE_mg_per_g_sample, color = run)) +
  geom_point(size = 2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_text_repel(aes(label = join_id), size = 3, max.overlaps = 20) +
  labs(
    title = "Measured vs. Predicted PE by Run",
    x = "Predicted PE (mg/g)",
    y = "Measured PE (mg/g)",
    color = "Run"
  ) +
  theme_minimal()
print(p1)
# Save plot
ggsave(filename = file.path("output PE/plots", "measured_vs_predicted_PE.png"), plot = p1, width = 6, height = 4)

# 2) Residuals vs Predicted
p2 <- ggplot(df_compare, aes(x = PE_pred_run2_mg_per_g, y = diff)) +
  geom_point( size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Residuals vs. Predicted",
    x = "Predicted PE (mg/g)",
    y = "Measured ‚Äì Predicted (mg/g)",
    color = "Run"
  ) +
  theme_minimal()

print(p2)
# Save plot
ggsave(filename = file.path(de, "residuals_vs_predicted_PE.png"), plot = p2, width = 6, height = 4)

# 3) Bland‚ÄìAltman plot
p3 <- ggplot(df_compare, aes(x = mean_PE, y = diff)) +
  geom_point(color = "darkgreen", size = 2) +
  geom_hline(yintercept = mean(df_compare$diff), color = "blue") +
  geom_hline(yintercept = mean(df_compare$diff) + 1.96 * sd(df_compare$diff),
             linetype = "dashed", color = "grey50") +
  geom_hline(yintercept = mean(df_compare$diff) - 1.96 * sd(df_compare$diff),
             linetype = "dashed", color = "grey50") +
  labs(
    title = "Bland‚ÄìAltman Plot",
    x = "Mean of Measured & Predicted PE (mg/g)",
    y = "Difference (Measured ‚Äì Predicted)"
  ) +
  theme_minimal()
print(p3)
# Save plot
ggsave(filename = file.path(de, "bland_altman_PE.png"), plot = p3, width = 6, height = 4)
```

```{r top20-differences}
# Extract and save top 20 samples with largest absolute differences
top20_diff <- df_compare %>%
  arrange(desc(diff_abs)) %>%
  slice(1:20) %>%
  select(join_id, run, PE_mg_per_g_sample, PE_pred_run2_mg_per_g, diff, diff_abs)

# Print top 20 to console
print(top20_diff)

# Create export directory for data if it doesn't exist
export_dir <- "output PE/export data"
if (!dir.exists(export_dir)) dir.create(export_dir, recursive = TRUE)


# Save to CSV in the export directory
write_csv(top20_diff, file.path(export_dir, "top20_PE_differences.csv"))
```



For each unique run in `combined_df`, we will:\
1.
**Filter to that run‚Äôs subset of data.**\
2.
**If the run has fewer than 4 samples, skip** with a warning.\
3.
**Fit three regression models:**\
- **Linear:**\
$$
       X_{\text{red}} \sim PE\_scaled
     $$\
- **Log:**\
$$
       X_{\text{red}} \sim \log\bigl(PE\_scaled + 0.001\bigr)
     $$\
- **Polynomial:**\
$$
       X_{\text{red}} \sim PE\_scaled \;+\; I\bigl(PE\_scaled^2\bigr)
     $$\
4.
**Extract R¬≤ and p‚Äêvalues** for each model using `get_stats()`.\
5.
**Build a ggplot** that:\
- Plots raw points (`geom_point`).\
- Adds fitted lines:\
- Blue = linear model\
- Green (dashed) = log model\
- Red (dot‚Äêdash) = polynomial model\
- Annotates each line‚Äôs R¬≤/p‚Äêvalue in the top‚Äêright corner.\
6.
**Save each run‚Äôs plot** under `plots/regression/<run>/Xred_PE_regressions_<run>.png`.\
7.
**Print each plot** so it appears in the knitted HTML.

```{r regression-by-run, fig.show='hold', fig.width=10, fig.height=6}
# 1. Ensure 'run' is treated as a factor
combined_df$run <- as.factor(combined_df$run)

# 2. Create base directory for all regression plots
reg_dir <- file.path("output PE", "plots", "pe_fluor_regressions")
dir.create(reg_dir, recursive = TRUE, showWarnings = FALSE)

# 3. Loop over each unique run identifier
for (r in unique(as.character(combined_df$run))) {
  # 3a. Subset to only this run
  # 3a. Subset to only this run
df_sub <- combined_df %>% filter(run == r)

# 3a.1 Clean the data
df_sub <- df_sub %>%
  filter(!is.na(PE_scaled), !is.na(Xred), 
         is.finite(PE_scaled), is.finite(Xred), 
         PE_scaled > -0.001)

# 3b. Skip if too few data points
if (nrow(df_sub) < 4) {
  warning(paste("Skipping run", r, "- not enough data (n =", nrow(df_sub), ")"))
  next
}
  
  # 3c. Fit models
  model_linear <- lm(Xred ~ PE_scaled, data = df_sub)
  model_log    <- lm(Xred ~ log(PE_scaled + 0.001), data = df_sub)
  model_poly   <- lm(Xred ~ PE_scaled + I(PE_scaled^2), data = df_sub)
  
  # 3d. Get stats
  ann_linear <- get_stats(model_linear, "Linear")
  ann_log    <- get_stats(model_log,    "Log")
  ann_poly   <- get_stats(model_poly,   "Poly")
  
  # 3e. Create plot
  p <- ggplot(df_sub, aes(x = PE_scaled, y = Xred)) +
    geom_point(alpha = 0.6, color = "black") +
    stat_smooth(method = "lm", formula = y ~ x, 
                se = FALSE, color = "blue") +
    stat_smooth(method = "lm", formula = y ~ log(x + 0.001), 
                se = FALSE, color = "green", linetype = "dashed") +
    stat_smooth(method = "lm", formula = y ~ x + I(x^2), 
                se = FALSE, color = "red", linetype = "dotdash") +
    annotate("text", x = Inf, y = Inf, label = ann_linear, 
             hjust = 1.05, vjust = 2, color = "blue", size = 4) +
    annotate("text", x = Inf, y = Inf, label = ann_log, 
             hjust = 1.05, vjust = 3.5, color = "green", size = 4) +
    annotate("text", x = Inf, y = Inf, label = ann_poly, 
             hjust = 1.05, vjust = 5, color = "red", size = 4) +
    theme_minimal() +
    labs(
      title = paste("Regression Models: Xred vs PE (", r, ")"),
      x     = "PE_scaled (mg/g sample √ó 1000)",
      y     = "Xred Fluorescence"
    )
  
  # 3f. Save the plot (all to one shared folder)
  filename <- paste0("Xred_PE_regressions_", r, ".png")
  ggsave(
    filename = file.path(reg_dir, filename),
    plot     = p,
    width    = 10,
    height   = 6,
    dpi      = 300,
    bg       = "white"
  )
  
  # 3g. Show plot in knitted HTML
  print(p)
}
```



## STEP 12: ANALYZE TECHNICAL REPLICATES

-   We need to process replicate measurements for each sample to calculate summary statistics (mean, standard deviation, standard error, coefficient of variation, etc.).\
-   The `analyze_replicates()` function will:
    1.  Group data by a sample identifier (`id_col`) and perform calculations on numeric columns (e.g., `PE_mg_per_g_sample`, `Xred`).\
    2.  Optionally select the best 3 replicates (when `choose_best_3 = TRUE`) by minimizing the coefficient of variation (CV) before calculating summary stats.\
    3.  Compute per‚Äêsample means, SDs, SEs, CVs, and maximum deviation percentages for each variable.\
    4.  Record the number of replicates, average weights, and list which replicates were included/excluded.\
    5.  Write a CSV file (`<output_prefix>_summary.csv`) with one row per sample, containing all summary metrics.\
    6.  Return a summary data frame in the global environment (named `<output_prefix>_summary`).

Below we run two passes of `analyze_replicates()` on `combined_df`: 1.
Without enhanced CV‚Äêbased selection (`choose_best_3 = FALSE`), saving as `all_rep_analy_summary.csv`.\
2.
With enhanced selection (`choose_best_3 = TRUE`), saving as `E_rep_analy_summary.csv`.\
Finally, we use `graph_histograms_with_error()` to plot histograms with error bars for key variables (`PE_mg_per_g_sample` and `Xred`).


```{r analyze-replicates, warning=FALSE}
# 1. Analyze replicates without enhanced (best-3) selection
analyze_replicates(
  data          = combined_df,
  id_col        = "ID",         # column that uniquely identifies each sample
  join_col      = "join_id",         # also used for joining, same as id_col here
  weight_col    = "sample weight",   # column containing sample weight in grams
  date_col      = "date",            # column containing sample collection date
  output_prefix = "all_rep_analy",   # prefix for output files (will produce all_rep_analy_summary.csv)
  choose_best_3 = FALSE, # do not filter replicates, use all
  dir = "output PE/export data/"
)

# 2. Analyze replicates with enhanced (best-3) selection by CV
analyze_replicates(
  data          = combined_df,
  id_col        = "ID",              # column uniquely identifying each sample
  join_col      = "join_id",         # join key for replicate grouping
  weight_col    = "sample weight",   # sample weight column (grams)
  date_col      = "date",            # collection date column
  output_prefix = "E_rep_analy",     # prefix for output files (will produce E_rep_analy_summary.csv)
  choose_best_3 = TRUE,
  dir = "output PE/export data/"
  # select the best 3 replicates (lowest CV) per sample
)
# 3. Generate histograms with error bars for key variables
## SAVE HISTOGRAMS WITH ERROR BARS AS PNGS
# Create output folder if it doesn't exist

```

## STEP 12.5: GENERATE HISTOGRAMS WITH ERROR BARS FOR MULTIPLE VARIABLES

- We want to create a bar plot (histogram) with error bars for each variable in a user‚Äêspecified list (e.g., `"PE_mg_per_g_sample"`, `"Xred"`).  
- For each variable, we assume there is a corresponding standard error column named `"<variable>_se"` (e.g., `"PE_mg_per_g_sample_se"`, `"Xred_se"`).  
- We will call `graph_replicates_custom_error()` once for each pair `(value_col, se_col)`.  
- The function will create its own output folder named `"<variable>_replicate_analysis_plots"` (based on `output_prefix`) and save a PNG of the bar plot with error bars.  
- Finally, we collect the returned interactive Plotly objects in a list, so they can be displayed in the HTML if desired.

```{r multiple-replicate-histograms, warning=FALSE}
# 1. Define the variables to plot
variables <- c("PE_mg_per_g_sample", "Xred", "X564")

# 2. Define shared output directory
rep_plot_dir <- file.path("output PE", "plots", "replicate_analysis")
dir.create(rep_plot_dir, recursive = TRUE, showWarnings = FALSE)

# 3. Read summary data
E_rep_analy_summary <- read.csv("output PE/export data/E_rep_analy_summary.csv")

# 4. Initialize list for interactive plotly plots
interactive_plots <- list()

# 5. Loop through each variable and generate plots
for (var in variables) {
  se_col_name    <- paste0(var, "_se")
  mean_col_name  <- paste0(var, "_mean")
  output_prefix  <- file.path(rep_plot_dir, paste0(var, "_replicate_analysis"))

  interactive_plot <- graph_replicates_custom_error(
    data          = E_rep_analy_summary,
    id_col        = "ID",
    value_col     = mean_col_name,
    se_col        = se_col_name,
    output_prefix = output_prefix  # e.g. PE/output_PE/plots/replicate_analysis/Xred_replicate_analysis
  )

  interactive_plots[[var]] <- interactive_plot
}

# 6. Display plots in R Markdown HTML output
htmltools::tagList(interactive_plots)



```

### Check the effect of Lorenas data
```{r}
Combined_df_before <- combined_df[combined_df$run != "4",]
analyze_replicates(
  data          = Combined_df_before,
  id_col        = "ID",              # column uniquely identifying each sample
  join_col      = "join_id",         # join key for replicate grouping
  weight_col    = "sample weight",   # sample weight column (grams)
  date_col      = "date",            # collection date column
  output_prefix = "E_rep_analy_before",
  choose_best_3 = TRUE,
  dir = "output PE/export data/"
  )
Before <- read.csv("output PE/export data/E_rep_analy_before_summary.csv")

E_rep_analy_summary <- E_rep_analy_summary[-1,]

se_change <- mean(E_rep_analy_summary$PE_mg_per_g_sample_se, na.rm = TRUE)- mean(Before$PE_mg_per_g_sample_se, na.rm=T)

paste("sample se for replicates change by:", se_change)
```



Check effects of enhancement algorithm

```{r}
PErep_enhanced <- read_csv("output PE/export data/E_rep_analy_summary.csv") #retrieve analized replicates from enhanced CV 
PErep_all <- read_csv("output PE/export data/all_rep_analy_summary.csv") #retrieve analized replicates without enhancement 
#Note, this is a product of analyze_replicates using enhanced replicate selection.
SE_change <- PErep_enhanced$PE_mg_per_g_sample_max_dev_pct -PErep_all$PE_mg_per_g_sample_max_dev_pct
print(SE_change)
SE_change <- SE_change[-51] #remove one NaN at the end
paste("# number of replicates SE acted upon:", length(SE_change[SE_change != 0]))
paste("average improvement by max deviation as a percent of the mean:", abs(mean(SE_change[SE_change != 0], na.rm = TRUE)))
```

------------------------------------------------------------------------

## STEP 13: JOIN ENHANCED REPLICATE ANALYSIS WITH SAMPLE METADATA AND RUN GROUP COMPARISONS

**Plain English:**

-   We want to merge the enhanced replicate‚Äêanalysis summary (`PErep_enhanced`) with our sample metadata (`Sample data`) so that we can run group‚Äêlevel comparisons (e.g., by location, variety, life stage).\
-   After joining:
    1.  We generate histograms with custom error bars for `PE_mg_per_g_sample_mean` using `graph_replicates_custom_error()`.\
    2.  We run `compare_groups()` four times to produce boxplots (with significance letters) for:
        -   **PE_mg_per_g_sample_mean** by **Location**\
        -   **Xred_mean** by **Location**\
        -   **PE_mg_per_g_sample_mean** by **variety**\
        -   **PE_mg_per_g_sample_mean** by **Life_S**\
-   Each plot is saved automatically by the respective function (if they write files), and printed to the HTML.

```{r final-join-and-comparisons, warning=FALSE}
# 1. Merge enhanced replicate summary with metadata by column "ID"
#    This will save "PErep_final.csv" and assign the merged data frame to `PErep_final`.
# 1. Define export folder and create it if needed
final_export_dir <- file.path("output PE", "export data", "Samples Analysis Final")
dir.create(final_export_dir, recursive = TRUE, showWarnings = FALSE)

# 2. Join PErep_enhanced with Sample data
joindf_by_id(
  df1          = PErep_enhanced,
  df2          = `Sample data`,
  output_name  = file.path(final_export_dir, "PErep_final.csv"),
  unmatched_out = file.path(final_export_dir, "PErep_unmatched.csv"),
  key_df1      = "ID",
  key_df2      = "ID"
)

# 3. Read in the joined summary
PErep_final <- readr::read_csv(file.path(final_export_dir, "PErep_final.csv"))

# 4. Define output directory for replicate analysis plots
rep_plot_dir <- file.path("output PE", "plots", "replicate_analysis")
dir.create(rep_plot_dir, recursive = TRUE, showWarnings = FALSE)

# 5. Generate histogram with error bars for PE_mg_per_g_sample_mean
graph_replicates_custom_error(
  data          = PErep_final,
  id_col        = "join_id",
  value_col     = "PE_mg_per_g_sample_mean",
  se_col        = "PE_mg_per_g_sample_se",
  output_prefix = file.path(rep_plot_dir, "E_rep_analy")
)

PE_location <- PErep_final %>%
  filter(!Location %in% c("Lima Market Freeze Dry", "Ilo Freeze Dry", "Ilo oven dry", "Ilo Fresh", "Lima Market Fresh"))

PE_location_cham <- PErep_final %>%
  filter(!variety %in% c("F.Glom"))
# 6. Run group comparisons and print outputs

###################################################Location
compare_groups(
  data         = PE_location_cham,
  response_var = "PE_mg_per_g_sample_mean",
  group_var    = "Location",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

compare_groups(
  data         = PE_location_cham,
  response_var = "PE_pred_run2_mg_per_g_mean",
  group_var    = "Location",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

################################################Life_S
compare_groups(
  data         = PE_location_cham,
  response_var = "PE_mg_per_g_sample_mean",
  group_var    = "Life_S",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

compare_groups(
  data         = PE_location_cham,
  response_var = "PE_pred_run2_mg_per_g_mean",
  group_var    = "Life_S",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

###########################################Variety
PE_paracas_marcona <- PErep_final %>%
  filter(Location %in% c("Mendieta", "7H", "Caro Caido"))

compare_groups(
  data         = PE_paracas_marcona,
  response_var = "PE_mg_per_g_sample_mean",
  group_var    = "variety",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

compare_groups(
  data         = PE_location_cham,
  response_var = "PE_pred_run2_mg_per_g_mean",
  group_var    = "variety",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

#################################Preperation method

PE_methods <- PErep_final %>%
  filter(Location %in% c("Lima Market Freeze Dry", "Ilo Freeze Dry", "Ilo oven dry", "Ilo Fresh", "Lima Market Fresh", "Lima Market Oven Dry"))

compare_groups(
  data         = PE_methods,
  response_var = "PE_mg_per_g_sample_mean",
  group_var    = "Location",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

compare_groups(
  data         = PE_methods,
  response_var = "PE_pred_run2_mg_per_g_mean",
  group_var    = "Location",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

#################################Gam Cham

PE_gamtetra <- PE_location %>%
  filter(Life_S %in% c("Gam/Tetra", "Gam", "Tetra"))

compare_groups(
  data         = PE_gamtetra,
  response_var = "PE_mg_per_g_sample_mean",
  group_var    = "Location",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)

compare_groups(
  data         = PE_gamtetra,
  response_var = "PE_pred_run2_mg_per_g_mean",
  group_var    = "Location",
  report_dir = "output PE/reports",
  plot_dir   = "output PE/plots"
)
```





