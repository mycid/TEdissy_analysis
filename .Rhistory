do.call(
cbind,
lapply(summaries, function(s) {
s_named <- as.list(s)
sapply(all_stats, function(k) s_named[[k]] %||% NA)
})
)
)
# 4. Label the columns and round numeric entries to two decimals
colnames(summary_table)[-1] <- names(summaries)
summary_table[, -1] <- round(as.data.frame(summary_table[, -1]), 2)
# 5. Print the table to the knitted HTML
print(summary_table)
#
# 7. Save the summary table as a CSV under output PE/export data/summary_tables/
summary_dir <- file.path("output PE", "export data", "summary_tables")
if (!dir.exists(summary_dir)) dir.create(summary_dir, recursive = TRUE)
write.csv(
summary_table,
file = file.path(summary_dir, "PE_Fluor_summary_stats.csv"),
row.names = FALSE
)
message("Summary statistics saved to: ", file.path(summary_dir, "PE_Fluor_summary_stats.csv"))
# 1. Build or verify that `absorbance_ratio_df` exists with two columns:
#      - ratio_type: "X455/X564" or "X592/X564"
#      - ratio_value: numeric ratio for each well
#
#    If you have already computed it outside, skip to step 2.
#    Example code to create it (uncomment and adjust if needed):
#
# 1. Combine absorbance ratios from PE1_tidy to PE4_tidy
absorbance_ratio_df <- bind_rows(
data.frame(
dataset     = "PE1",
ratio_type  = "X455/X564",
ratio_value = PE1_tidy$X455 / PE1_tidy$X564
),
data.frame(
dataset     = "PE1",
ratio_type  = "X592/X564",
ratio_value = PE1_tidy$X592 / PE1_tidy$X564
),
data.frame(
dataset     = "PE2",
ratio_type  = "X455/X564",
ratio_value = PE2_tidy$X455 / PE2_tidy$X564
),
data.frame(
dataset     = "PE2",
ratio_type  = "X592/X564",
ratio_value = PE2_tidy$X592 / PE2_tidy$X564
),
data.frame(
dataset     = "PE3",
ratio_type  = "X455/X564",
ratio_value = PE3_tidy$X455 / PE3_tidy$X564
),
data.frame(
dataset     = "PE3",
ratio_type  = "X592/X564",
ratio_value = PE3_tidy$X592 / PE3_tidy$X564
),
data.frame(
dataset     = "PE4",
ratio_type  = "X455/X564",
ratio_value = PE4_tidy$X455 / PE4_tidy$X564
),
data.frame(
dataset     = "PE4",
ratio_type  = "X592/X564",
ratio_value = PE4_tidy$X592 / PE4_tidy$X564
)
)
# 2. Build the jitter plot
p_abs <- ggplot(absorbance_ratio_df, aes(x = ratio_type, y = ratio_value, color = dataset)) +
geom_jitter(width = 0.1, alpha = 0.6) +
geom_hline(yintercept = 1.0, linetype = "dashed", color = "red") +
labs(
title = "Absorbance Ratios: X455/X564 and X592/X564",
x     = "Absorbance Ratio Type",
y     = "Ratio Value"
) +
theme_minimal()
# 3. Save to disk under output PE/plots/absorbance/
absorbance_dir <- file.path("output PE", "plots", "absorbance")
if (!dir.exists(absorbance_dir)) dir.create(absorbance_dir, recursive = TRUE)
ggsave(
filename = file.path(absorbance_dir, "Absorbance_Ratio_X455_X592.png"),
plot     = p_abs,
width    = 10,
height   = 6,
dpi      = 300,
bg       = "white"
)
# 4. Print so it appears in the knitted HTML
print(p_abs)
# 1. Create output subdirectory
save_dir <- file.path("output_PE", "export data", "joined_weights_PE")
dir.create(save_dir, recursive = TRUE, showWarnings = FALSE)
# 2. Build weight and PE data frame lists
list_weights <- list(
pe1_weights_id,
pe2_weights_id,
pe3_weights_id,
pe4_weights_id
)
PE_list <- list(
PE1 = PE1_tidy,
PE2 = PE2_tidy,
PE3 = PE3_tidy,
PE4 = PE4_tidy
)
# 3. Loop and join
mapply(
function(df1, df2, name) {
joindf_by_id(
df1          = df1,
df2          = df2,
output_name  = file.path(save_dir, paste0(name, "_weights_joined.csv")),
unmatched_out = file.path(save_dir, paste0(name, "_weights_unmatched.csv")),
key_df1      = "Cell_ID",
key_df2      = "plate well"
)
},
df1 = PE_list,
df2 = list_weights,
name = names(PE_list),
SIMPLIFY = FALSE
)
# Create export subdirectory for filtered PE data
# Create export subdirectory for filtered PE data
pe_filtered_dir <- file.path("output PE", "export data", "pe filtered")
dir.create(pe_filtered_dir, recursive = TRUE, showWarnings = FALSE)
# List of input dataframes
joined_data <- list(
PE1 = PE1_weights_joined,
PE2 = PE2_weights_joined,
PE3 = PE3_weights_joined,
PE4 = PE4_weights_joined
)
# Run calculate_pe_and_filter() for each dataset
invisible(
mapply(function(df, name) {
calculate_pe_and_filter(
tidy_df = df,
output_basename = paste0(name, "_calc"),
sample_id_col = "join_id",
sample_weight_col = "sample weight"  # <- correct column name
)
},
df   = joined_data,
name = names(joined_data),
SIMPLIFY = FALSE)
)
# 0. Setup output directory for plots
plot_dir <- file.path("output PE", "plots", "fluorescence_xred")
dir.create(plot_dir, recursive = TRUE, showWarnings = FALSE)
# 1. Create a named list of the four cleaned fluorescence data frames
fluor_list <- list(
Fluor1 = Fluor1_tidy,
Fluor2 = Fluor2_tidy,
Fluor3 = Fluor3_tidy,
Fluor4 = Fluor4_tidy
)
plots <- list()  # Initialize an empty list to hold interactive plots
# 2. Loop through each Fluorescence run and generate plots
for (name in names(fluor_list)) {
df <- fluor_list[[name]]
# 2a. Build a ggplot bar chart of Xred by Cell_ID
p <- ggplot(df, aes(x = Cell_ID, y = Xred)) +
geom_bar(stat = "identity", fill = "skyblue") +
geom_text(aes(label = round(Xred, 3)), vjust = -0.5, size = 3) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
) +
labs(
title = paste("Raw Xred Fluorescence –", name),
x     = "Sample (Cell_ID)",
y     = "Xred Fluorescence"
)
# 2b. Save the static PNG version to the subdirectory
filename <- file.path(plot_dir, paste0(name, "_fluorescence.png"))
ggsave(
filename = filename,
plot     = p,
width    = 10,
height   = 6,
dpi      = 300,
bg       = "white"
)
# 2c. Convert to an interactive Plotly object and store
plots[[name]] <- ggplotly(p)
}
# 3. Display all interactive plots in the R Markdown HTML output
library(htmltools)
tagList(plots)
# Create subdirectory for this join group
pe_fluor_dir <- file.path("output PE", "export data", "pe_fluor_joins")
dir.create(pe_fluor_dir, recursive = TRUE, showWarnings = FALSE)
# Run joins with explicit output paths
joindf_by_id(
df1 = PE1_calc,
df2 = Fluor1_tidy,
output_name   = file.path(pe_fluor_dir, "pe_fluor1_joined.csv"),
unmatched_out = file.path(pe_fluor_dir, "pe_fluor1_unmatched.csv"),
key_df1 = "join_id",
key_df2 = "Cell_ID"
)
joindf_by_id(
df1 = PE2_calc,
df2 = Fluor2_tidy,
output_name   = file.path(pe_fluor_dir, "pe_fluor2_joined.csv"),
unmatched_out = file.path(pe_fluor_dir, "pe_fluor2_unmatched.csv"),
key_df1 = "join_id",
key_df2 = "Cell_ID"
)
joindf_by_id(
df1 = PE3_calc,
df2 = Fluor3_tidy,
output_name   = file.path(pe_fluor_dir, "pe_fluor3_joined.csv"),
unmatched_out = file.path(pe_fluor_dir, "pe_fluor3_unmatched.csv"),
key_df1 = "join_id",
key_df2 = "Cell_ID"
)
joindf_by_id(
df1 = PE4_calc,
df2 = Fluor4_tidy,
output_name   = file.path(pe_fluor_dir, "pe_fluor4_joined.csv"),
unmatched_out = file.path(pe_fluor_dir, "pe_fluor4_unmatched.csv"),
key_df1 = "join_id",
key_df2 = "Cell_ID"
)
# Rename columns in one of the joined results (after it has been auto-assigned)
#colnames(pe_fluor4)[colnames(pe_fluor4_joined) == "sample ID"] <- "ID"
# Combine all joined dataframes into a list
pe_fluor_all <- list(pe_fluor1_joined, pe_fluor2_joined, pe_fluor3_joined, pe_fluor4_joined)
# Add a run identifier to each dataframe
pe_fluor_all <- Map(function(df, i) {
df$run <- factor(paste0("run", i))
df
}, pe_fluor_all, seq_along(pe_fluor_all))
# Find common columns across all runs
common_cols <- Reduce(intersect, lapply(pe_fluor_all, names))
# Optional: harmonize date columns if needed
pe_fluor_all <- lapply(pe_fluor_all, function(df) {
df[] <- lapply(df, function(col) {
is_colname_date <- grepl("date", names(df)[which(sapply(df, identical, col))], ignore.case = TRUE)
if (inherits(col, "character") && is_colname_date) {
tryCatch(as.Date(col, format = "%m/%d/%Y"),
error = function(e) as.Date(col, format = "%d/%m/%Y"))
} else {
col
}
})
df
})
# Keep only the common columns in each dataframe before binding
combined_df <- bind_rows(
lapply(pe_fluor_all, function(df) df[common_cols]),
.id = "run"
)
#Finally merge all spreadsheets into one for replicate testing and analysis
#Scale PE bigger for regression purposes
combined_df <- combined_df %>%
mutate(PE_scaled = PE_mg_per_g_sample * 1000)
# Build a scatterplot of Xred vs. PE_mg_per_g_sample, colored by run
# Define directory for this plot group
pe_fluor_plot_dir <- file.path("output PE", "plots", "pe_fluor")
dir.create(pe_fluor_plot_dir, recursive = TRUE, showWarnings = FALSE)
# Create combined plot
p_all <- ggplot(combined_df, aes(x = PE_mg_per_g_sample, y = Xred, color = run)) +
geom_point(alpha = 0.6) +
theme_minimal() +
labs(
title = "Xred vs. PE_mg_per_g_sample (All Runs)",
x     = "PE (mg/g sample)",
y     = "Xred Fluorescence",
color = "Run"
) +
scale_color_brewer(palette = "Dark2") +
coord_cartesian(xlim = c(0, 0.5))
# Save the plot to the new subdirectory
ggsave(
filename = file.path(pe_fluor_plot_dir, "Xred_vs_PE_all_runs.png"),
plot     = p_all,
width    = 10,
height   = 6,
dpi      = 300,
bg       = "white"
)
# Display the plot in the knitted HTML
print(p_all)
# 1. Remove unwanted rows (190 to 194)
combined_df <- combined_df[-(191:194), ]
#
# 2. Add a new factor level "run 3 fresh" to the 'run' factor
levels(combined_df$run) <- c(levels(combined_df$run), "fresh run 3 & 4")
# 3. Assign "run 3 fresh" to rows 169:189
combined_df$run[169:189] <- "fresh run 3 & 4"
#
combined_df$run[209:213] <- "fresh run 3 & 4"
combined_df <- combined_df[-(214:215), ]
# 1. Ensure 'run' is treated as a factor
combined_df$run <- as.factor(combined_df$run)
# 2. Create base directory for all regression plots
reg_dir <- file.path("output PE", "plots", "pe_fluor_regressions")
dir.create(reg_dir, recursive = TRUE, showWarnings = FALSE)
# 3. Loop over each unique run identifier
for (r in unique(as.character(combined_df$run))) {
# 3a. Subset to only this run
df_sub <- combined_df %>% filter(run == r)
# 3b. Skip if too few data points
if (nrow(df_sub) < 4) {
warning(paste("Skipping run", r, "- not enough data (n =", nrow(df_sub), ")"))
next
}
# 3c. Fit models
model_linear <- lm(Xred ~ PE_scaled, data = df_sub)
model_log    <- lm(Xred ~ log(PE_scaled + 0.001), data = df_sub)
model_poly   <- lm(Xred ~ PE_scaled + I(PE_scaled^2), data = df_sub)
# 3d. Get stats
ann_linear <- get_stats(model_linear, "Linear")
ann_log    <- get_stats(model_log,    "Log")
ann_poly   <- get_stats(model_poly,   "Poly")
# 3e. Create plot
p <- ggplot(df_sub, aes(x = PE_scaled, y = Xred)) +
geom_point(alpha = 0.6, color = "black") +
stat_smooth(method = "lm", formula = y ~ x,
se = FALSE, color = "blue") +
stat_smooth(method = "lm", formula = y ~ log(x + 0.001),
se = FALSE, color = "green", linetype = "dashed") +
stat_smooth(method = "lm", formula = y ~ x + I(x^2),
se = FALSE, color = "red", linetype = "dotdash") +
annotate("text", x = Inf, y = Inf, label = ann_linear,
hjust = 1.05, vjust = 2, color = "blue", size = 4) +
annotate("text", x = Inf, y = Inf, label = ann_log,
hjust = 1.05, vjust = 3.5, color = "green", size = 4) +
annotate("text", x = Inf, y = Inf, label = ann_poly,
hjust = 1.05, vjust = 5, color = "red", size = 4) +
theme_minimal() +
labs(
title = paste("Regression Models: Xred vs PE (", r, ")"),
x     = "PE_scaled (mg/g sample × 1000)",
y     = "Xred Fluorescence"
)
# 3f. Save the plot (all to one shared folder)
filename <- paste0("Xred_PE_regressions_", r, ".png")
ggsave(
filename = file.path(reg_dir, filename),
plot     = p,
width    = 10,
height   = 6,
dpi      = 300,
bg       = "white"
)
# 3g. Show plot in knitted HTML
print(p)
}
# 1. Analyze replicates without enhanced (best-3) selection
analyze_replicates(
data          = combined_df,
id_col        = "ID",         # column that uniquely identifies each sample
join_col      = "join_id",         # also used for joining, same as id_col here
weight_col    = "sample weight",   # column containing sample weight in grams
date_col      = "date",            # column containing sample collection date
output_prefix = "all_rep_analy",   # prefix for output files (will produce all_rep_analy_summary.csv)
choose_best_3 = FALSE           # do not filter replicates, use all
)
# 2. Analyze replicates with enhanced (best-3) selection by CV
analyze_replicates(
data          = combined_df,
id_col        = "ID",              # column uniquely identifying each sample
join_col      = "join_id",         # join key for replicate grouping
weight_col    = "sample weight",   # sample weight column (grams)
date_col      = "date",            # collection date column
output_prefix = "E_rep_analy",     # prefix for output files (will produce E_rep_analy_summary.csv)
choose_best_3 = TRUE               # select the best 3 replicates (lowest CV) per sample
)
# 3. Generate histograms with error bars for key variables
## SAVE HISTOGRAMS WITH ERROR BARS AS PNGS
# Create output folder if it doesn't exist
# 1. Define the variables to plot
variables <- c("PE_mg_per_g_sample", "Xred", "X564")
# 2. Define shared output directory
rep_plot_dir <- file.path("PE", "output_PE", "plots", "replicate_analysis")
dir.create(rep_plot_dir, recursive = TRUE, showWarnings = FALSE)
# 3. Read summary data
E_rep_analy_summary <- read.csv("E_rep_analy_summary.csv")
# 4. Initialize list for interactive plotly plots
interactive_plots <- list()
# 5. Loop through each variable and generate plots
for (var in variables) {
se_col_name    <- paste0(var, "_se")
mean_col_name  <- paste0(var, "_mean")
output_prefix  <- file.path(rep_plot_dir, paste0(var, "_replicate_analysis"))
interactive_plot <- graph_replicates_custom_error(
data          = E_rep_analy_summary,
id_col        = "ID",
value_col     = mean_col_name,
se_col        = se_col_name,
output_prefix = output_prefix  # e.g. PE/output_PE/plots/replicate_analysis/Xred_replicate_analysis
)
interactive_plots[[var]] <- interactive_plot
}
# 6. Display plots in R Markdown HTML output
htmltools::tagList(interactive_plots)
Combined_df_before <- combined_df[combined_df$run != "4",]
analyze_replicates(
data          = Combined_df_before,
id_col        = "ID",              # column uniquely identifying each sample
join_col      = "join_id",         # join key for replicate grouping
weight_col    = "sample weight",   # sample weight column (grams)
date_col      = "date",            # collection date column
output_prefix = "E_rep_analy_before",
choose_best_3 = TRUE
)
Before <- read.csv("E_rep_analy_before_summary.csv")
E_rep_analy_summary <- E_rep_analy_summary[-1,]
se_change <- mean(E_rep_analy_summary$PE_mg_per_g_sample_se, na.rm = TRUE)- mean(Before$PE_mg_per_g_sample_se, na.rm=T)
paste("sample se for replicates change by:", se_change)
PErep_enhanced <- read_csv("E_rep_analy_summary.csv") #retrieve analized replicates from enhanced CV
PErep_all <- read_csv("all_rep_analy_summary.csv") #retrieve analized replicates without enhancement
#Note, this is a product of analyze_replicates using enhanced replicate selection.
SE_change <- PErep_enhanced$PE_mg_per_g_sample_max_dev_pct -PErep_all$PE_mg_per_g_sample_max_dev_pct
print(SE_change)
SE_change <- SE_change[-51] #remove one NaN at the end
paste("# number of replicates SE acted upon:", length(SE_change[SE_change != 0]))
paste("average improvement by max deviation as a percent of the mean:", abs(mean(SE_change[SE_change != 0], na.rm = TRUE)))
# 1. Merge enhanced replicate summary with metadata by column "ID"
#    This will save "PErep_final.csv" and assign the merged data frame to `PErep_final`.
# 1. Define export folder and create it if needed
final_export_dir <- file.path("PE", "output_PE", "export data", "PErep_joined")
dir.create(final_export_dir, recursive = TRUE, showWarnings = FALSE)
# 2. Join PErep_enhanced with Sample data
joindf_by_id(
df1          = PErep_enhanced,
df2          = `Sample data`,
output_name  = file.path(final_export_dir, "PErep_final.csv"),
unmatched_out = file.path(final_export_dir, "PErep_unmatched.csv"),
key_df1      = "ID",
key_df2      = "ID"
)
# 3. Read in the joined summary
PErep_final <- readr::read_csv(file.path(final_export_dir, "PErep_final.csv"))
# 4. Define output directory for replicate analysis plots
rep_plot_dir <- file.path("PE", "output_PE", "plots", "replicate_analysis")
dir.create(rep_plot_dir, recursive = TRUE, showWarnings = FALSE)
# 5. Generate histogram with error bars for PE_mg_per_g_sample_mean
graph_replicates_custom_error(
data          = PErep_final,
id_col        = "join_id",
value_col     = "PE_mg_per_g_sample_mean",
se_col        = "PE_mg_per_g_sample_se",
output_prefix = file.path(rep_plot_dir, "E_rep_analy")
)
# 5. Generate histogram with error bars for PE_mg_per_g_sample_mean
graph_replicates_custom_error(
data          = PErep_final,
id_col        = "join_id",
value_col     = "PE_mg_per_g_sample_mean",
se_col        = "PE_mg_per_g_sample_se",
output_prefix = file.path(rep_plot_dir, "E_rep_analy")
)
# 6. Run group comparisons and print outputs
compare_groups(
data         = PErep_final,
response_var = "PE_mg_per_g_sample_mean",
group_var    = "Location"
)
# 6. Run group comparisons and print outputs
compare_groups(
data         = PErep_final,
response_var = "PE_mg_per_g_sample_mean",
group_var    = "Location"
)
compare_groups(
data         = PErep_final,
response_var = "Xred_mean",
group_var    = "Location"
)
compare_groups(
data         = PErep_final,
response_var = "PE_mg_per_g_sample_mean",
group_var    = "variety"
)
compare_groups(
data         = PErep_final,
response_var = "PE_mg_per_g_sample_mean",
group_var    = "variety"
)
compare_groups(
data         = PErep_final,
response_var = "PE_mg_per_g_sample_mean",
group_var    = "Life_S"
)
# 1. Create export folder for "Red" variety comparisons
red_comp_dir <- file.path("PE", "output_PE", "export data", "PErep_comparisons_red")
dir.create(red_comp_dir, recursive = TRUE, showWarnings = FALSE)
# 2. Subset data for variety == "Gam/Tetra"
df_var_gamtetra <- PErep_final %>%
filter(variety == "Gam/Tetra")
View(PErep_final)
# 2. Subset data for variety == "gam/Tetra"
df_var_gamtetra <- PErep_final %>%
filter(Life_S == "Gam/Tetra")
# 2. Subset data for variety == "gam/Tetra"
df_var_gamtetra <- PErep_final %>%
filter(Life_S == "Gam/Tetra" | "Gam" | "Tetra")
# 2. Subset data for variety == "gam/Tetra"
df_var_gamtetra <- PErep_final %>%
filter(Life_S %in% c("Gam/Tetra", "Gam", "Tetra"))
