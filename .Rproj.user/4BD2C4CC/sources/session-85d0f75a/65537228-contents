---
title: "PE diagnostics"
author: "Trevor Eakes"
date: "`r Sys.Date()`"
output: html_document
params:
  wd: "G:/My Drive/ACES/Dissy/analysis/PE"
  input_file: "PE_2 13_5_25.xlsx"
  output_file: "tidy_final_PE 2_13_5_25.csv"
  blanks: ["A01", "A02", "A03"] #which are the blanks for the input file 
---

This Script analyizes absorption and flouresence data from all observations in my study of [C. Chamissoi](https://algaex.pe/en/raw-materials/alga-chondracanthus-chamissoi/)

::: {style="display: flex; justify-content: center; gap: 20px; margin: 20px 0;"}
<img src="https://algaex.pe/wp-content/uploads/2021/05/Chondracanthus.chamissoi.jpg" alt="Chondracanthus chamissoi" style="max-width: 45%; border-radius:12px; box-shadow: 4px 4px 15px rgba(0,0,0,0.35);"/> <img src="https://upload.wikimedia.org/wikipedia/commons/2/27/Phycoerythrin.png" alt="Phycoerythrin pigment" style="max-width: 45%; border-radius:12px; box-shadow: 4px 4px 15px rgba(0,0,0,0.35);"/>
:::

Scripts are sourced from the `process_plate_run` R script and called upon in this Markdown.
You must store the script in the working directory as well as all input and output files.
Go ahead and pick the directory you want to use.

```{r, warning = FALSE}
source("process_plate_run.R") #Contains all the functions I have built
```

WE FIRST LOAD THE INPUT FILES. Our project has three phycoerythrin and three complimentary fluoresence data sheets.
We also have three spreadsheets for sample weights, and a datasheet for our replicates.
We are going to upload all xlsx files and convert them into dataframe objects, retaining their file names using the load_excel_files function.

```{r warning=FALSE}
load_excel_files("Input PE")
```

# STEP 1: CONVERT THE DATA INTO A USABLE FORMAT

The `tidy_all` wrapper function and it's subordinated function `tidy_and_correct` processes spectral absorbency data from a multi-wavelength microplate reader assay to quantify phycoerythrin (PE) content in biological samples.
It performs the following key steps:

1.  **Data Import and Cleaning:**\
    Loads raw data from an Excel file (second sheet), removes header rows, and fills missing row identifiers for well labels.

2.  **Data Reshaping:**\
    Organizes the spectral data from multiple wavelengths into a tidy format where each row corresponds to a single well and each column to a specific wavelength measurement.

3.  **Blank Correction:**\
    Averages absorbance values from specified blank wells (e.g., `A01`, `A02`, `A03`) and subtracts these values from all sample wells to correct for background signal.

4.  **Quality Filtering:**\
    Removes any samples with negative absorbance values at any measured wavelength, tracking and reporting which samples were removed and for which wavelength(s).
    Compares absorbance at X565 and X564.

------------------------------------------------------------------------

FLUORESENCE AND ABSORBANCE ANALYSIS

## üîÑ Data Preparation and Tidy Processing

```{r}
# Define blank sample wells for each experimental run
blanks1 <- "A01"
blanks2 <- c("A01", "A02", "A03")
blanks3 <- c("H09", "H10", "H11")

# Create named lists of raw dataframes and corresponding blanks
listPE <- list(PE1 = PE1, PE2 = PE2, PE3 = PE3)
listFluor <- list(Fluor1 = Fluor1, Fluor2 = Fluor2, Fluor3 = Fluor3)
listblank <- list(blanks1, blanks2, blanks3)

# Clean and structure all datasets using a custom `tidy_all()` function
tidy_all(listPE, listblank)
tidy_all(listFluor, listblank)
```

All tidied up now!
‚úÖ \## üìä Summary Statistics Table

# STEP 2: REVIEW ABSORBANCE

```{r}
# Create named summaries of cleaned fluorescence and absorbance data
summaries <- list(
  Fluor1 = summary(Fluor1_tidy$Xred),
  Fluor2 = summary(Fluor2_tidy$Xred),
  Fluor3 = summary(Fluor3_tidy$Xred),
  PE1    = summary(PE1_tidy$X565),
  PE2    = summary(PE2_tidy$X565),
  PE3    = summary(PE3_tidy$X565)
)

# Combine into a single summary table
all_stats <- unique(unlist(lapply(summaries, names)))
summary_table <- data.frame(
  Statistic = all_stats,
  do.call(cbind, lapply(summaries, function(s) {
    s_named <- as.list(s)
    sapply(all_stats, function(k) s_named[[k]] %||% NA)
  }))
)
colnames(summary_table)[-1] <- names(summaries)
summary_table[,-1] <- round(summary_table[,-1], 2)
print(summary_table)
```

## ‚ûï Difference Calculation for PE Absorbance

```{r}
# Compute difference between 565 and 564 nm absorbance for each PE dataset
PE_list <- list(PE1_tidy = PE1_tidy, PE2_tidy = PE2_tidy, PE3_tidy = PE3_tidy)
PE_list <- lapply(PE_list, function(df) {
  df %>% dplyr::mutate(diff_absorbance = X565 - X564)
})
list2env(PE_list, envir = .GlobalEnv)  # Save updated datasets to global environment
```

## üìà Generate and Save Absorbance Difference Plots

```{r}
# For each tidy PE dataset, plot `diff_absorbance` by Cell_ID and save as PNG

plots <- list()  # Initialize empty list to store plots

for (name in names(PE_list)) {
  df <- PE_list[[name]]
  
  p <- ggplot(df, aes(x = Cell_ID, y = diff_absorbance)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    geom_text(aes(label = round(diff_absorbance, 3)), vjust = -0.5, size = 3) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
    labs(
      title = paste("Difference between 565 and 564 Absorbance -", name),
      x = "Sample (Cell_ID)",
      y = "Difference (X565 - X564)"
    )
  
  # Save static plot as PNG (optional)
  ggsave(paste0(name, "_diff_absorbance.png"), plot = p, width = 10, height = 6, dpi = 300)
  
  # Store interactive plot in the list
  plots[[name]] <- ggplotly(p)
}

# Display all interactive plots in your HTML output
htmltools::tagList(plots)
```

## üìà Look for interference from other spectra measured

```{r}
df_ratios <- PE2_tidy %>%
  mutate(
    `X455/X564` = X455 / X564,
    `X592/X564` = X592 / X564,
    Sample = row_number()
  ) %>%
  pivot_longer(cols = c(`X455/X564`, `X592/X564`), names_to = "Ratio", values_to = "Value")

# Plot
  
ggplot(df_ratios, aes(x = Ratio, y = Value)) +
  geom_boxplot() +
  geom_jitter(width = 0.1, alpha = 0.5, color = "black") +
  geom_hline(yintercept = 1.0, linetype = "dashed", color = "red") +
  labs(
    title = "Relative Absorbance: X455 and X592 Compared to X564",
    y = "Absorbance Ratio",
    x = "Absorbance Ratio Type"
  ) +
  theme_minimal()

```

# STEP 3: JOIN THE DATA WITH ITS SAMPLE WEIGHTS SPREADSHEET

\### Description of `joindf_by_id` Function

The `joindf_by_id` function takes two data frames (`df1` and `df2`) and merges them by matching unique identifiers related to samples, specifically using either a `Cell_ID` column or a `plate well` column.
The key steps and features are:

-   **Column Cleaning:** It trims whitespace from column names in both data frames to avoid join errors caused by accidental spaces.
-   **Key Column Verification:** It checks that at least one of the data frames contains a `Cell_ID` column and the other contains a `plate well` column, which serve as the join keys.
-   **Role Assignment:** Depending on which data frame contains the `Cell_ID` column, that data frame is assigned as the base (`df_cell`), and the other as the joining data (`df_plate`).
-   **Rename Join Keys:** The columns used for joining are renamed to a common key (`join_id`) to facilitate the join.
-   **Perform Join:** The function performs a left join, keeping all rows from the smaller data frame and adding matching data from the other.
-   **Identify Unmatched Rows:** Rows present in the larger data frame but missing matches in the smaller one are saved separately.
-   **Output Files:** The merged data frame is saved as a CSV file named according to the provided `output_name`. Additionally, unmatched rows are saved in a separate CSV file.
-   **Global Environment Assignment:** The merged data frame is also assigned as a variable in the global R environment for easy access.
-   **Reporting:** The function prints messages listing any unmatched identifiers that ‚Äúneed to be repeated‚Äù and returns a summary report including counts of matched and unmatched rows and file paths of the saved CSVs.

```{r, warning = FALSE}
#Set up new list of weights data to join
list_weights<- list(pe1_weights_id, pe2_weights_id, pe3_weights_id)

# Loop through both lists in parallel
mapply(function(df1, df2, name) {
  output_file <- paste0(name, "_joined.csv")
  joindf_by_id(df1, df2, output_file, key_df1 = "Cell_ID", key_df2 = "plate well")
}, df1 = PE_list, df2 = list_weights, name = names(listPE))
```

STEP 4: CALCULATE PE CONTENT![Purified phycoerythrin representation](https://algae-products.com/wp-content/uploads/2023/05/pink.jpg) Calculating PE This function takes a tidy data frame containing absorbance measurements and calculates the concentration of phycoerythrin (PE) for each sample based on the Beer & Eshel (1985) method.
It performs the following steps:

1.  **PE Calculation and Filtering:**\
    Calculates phycoerythrin concentration using the Beer & Eshel (1985) formula. Samples with negative PE values are also removed and reported. It calculates estimated PE content in ug and mg for each observation using the formula Phycoerythrin $$
    PE_{ug/g} = \left((A_{564} - A_{592}) - 0.20 \times (A_{455} - A_{592})\right) \times 0.12
    $$

from Beer S, Eshel A (1985) Determining phycoerythrin and phycocyanin concentrations in aqueous crude extracts of red algae.
Aust J Mar Freshwater Res 36:785‚Äì792, <https://doi.org/10.1071/MF9850785>.

2.  **Filtering Negative PE Values:**\
    Samples with negative PE concentrations are identified and removed.
    These removed samples are printed in the console with the reason for removal.

3.  **Normalization to Sample Weight:**\
    The PE concentration is converted from micrograms per milliliter (¬µg/mL) to milligrams per gram of dry sample (mg/g) by adjusting for the extract volume and the individual sample weights provided in the data frame.
    This ensures accurate PE quantification based on the exact weight of each sample rather than using a fixed default weight.

4.  **Output and Metadata:**\
    The function returns a filtered data frame containing valid samples with their calculated PE concentrations in mg/g.
    Additionally, it stores the filtered-out rows (samples with negative PE) as an attribute called `"removed_rows_pe"` for further inspection if needed.

This process helps ensure the quality and accuracy of PE measurements by excluding invalid data and normalizing concentrations based on actual sample weights.

```{r}
PE1_calc <- calculate_pe_and_filter(PE1_joined, sample_weight_col = "sample weight", sample_id_col="join_id")
PE2_calc <- calculate_pe_and_filter(PE2_joined, sample_weight_col = "sample weight", sample_id_col="join_id")
PE3_calc <- calculate_pe_and_filter(PE3_joined, sample_weight_col = "sample weight", sample_id_col="join_id")
```

# STEP 5: FLUORESENCE DATA VISUALIZATION

```{r, warning=FALSE}

fluor_list <- list(
  Fluor1 = Fluor1_tidy,
  Fluor2 = Fluor2_tidy,
  Fluor3 = Fluor3_tidy
)

library(ggplot2)
library(plotly)
library(htmltools)

plots <- list()  # Initialize empty list to store interactive plots

for (name in names(fluor_list)) {
  df <- fluor_list[[name]]
  
  p <- ggplot(df, aes(x = Cell_ID, y = Xred)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    geom_text(aes(label = round(Xred, 3)), vjust = -0.5, size = 3) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
    labs(
      title = paste("530/25,590/35 -", name),
      x = "Sample (Cell_ID)",
      y = "Fluorescence"
    )
  
  # Save static version of plot (optional)
  filename <- paste0(name, "_fluorescence.png")
  ggsave(filename, plot = p, width = 10, height = 6, dpi = 300)
  
  # Store the interactive version of the plot
  plots[[name]] <- ggplotly(p)
}

# Display all interactive plots together in the HTML output
htmltools::tagList(plots)


```

# STEP 6: FLUORESENCE DATA JOIN

Lets join this data to the PE data that has already been joined with the weights and id's table.

```{r, warning=FALSE}
joindf_by_id(PE1_calc, Fluor1_tidy, "pe_fluor1.csv", key_df1 = "join_id", key_df2 = "Cell_ID")
joindf_by_id(PE2_calc, Fluor2_tidy, "pe_fluor2.csv", key_df1 = "join_id", key_df2 = "Cell_ID")
joindf_by_id(PE3_calc, Fluor3_tidy, "pe_fluor3.csv", key_df1 = "join_id", key_df2 = "Cell_ID")

pe_fluor_all <- list(pe_fluor1, pe_fluor2, pe_fluor3)

# Add a run column based on list position
pe_fluor_all <- Map(function(df, i) {
  df$run <- factor(paste0("run", i))
  df
}, pe_fluor_all, seq_along(pe_fluor_all))

common_cols <- Reduce(intersect, lapply(pe_fluor_all, names))

# Keep only the common columns in each dataframe before binding
combined_df <- bind_rows(
  lapply(pe_fluor_all, function(df) df[common_cols]),
  .id = "run"
)
#Finally merge all spreadsheets into one for replicate testing and analysis
#Scale PE bigger for regression purposes
combined_df <- combined_df %>%
  mutate(PE_scaled = PE_mg_per_g_sample * 1000)

```

1Ô∏è‚É£ Full Dataset Plot with Points Colored by Run

```{r}
p_all <- ggplot(combined_df, aes(x = PE_mg_per_g_sample, y = Xred, color = run)) +
  geom_point(alpha = 0.6) +
  theme_minimal() +
  labs(title = "Xred vs PE_mg_per_g_sample (All Runs)",
       x = "PE (mg/g sample)",
       y = "Xred Fluorescence") +
  scale_color_brewer(palette = "Dark2")

ggsave("Xred_PE_all_runs.png", plot = p_all, width = 10, height = 6, dpi = 300)
print(p_all)

# Remove unwanted rows first
combined_df <- combined_df[-(190:194), ]

# Add new factor level before assignment
levels(combined_df$run) <- c(levels(combined_df$run), "run 3 fresh")

# Assign new factor value to rows 169 to 189 (adjusted for new row count)
combined_df$run[169:189] <- "run 3 fresh"
```

2Ô∏è‚É£ Loop Through Each Run and Save Regressions

```{r}
runs <- levels(combined_df$run)
for (r in runs) {
  df_sub <- combined_df %>% filter(run == r)

  if (nrow(df_sub) < 4) {
    warning(paste("Skipping run", r, "- not enough data"))
    next
  }
#df_sub <- combined_df %>% filter(run == "run1")
  # Fit models
  model_linear <- lm(Xred ~ PE_scaled, data = df_sub)
  model_log    <- lm(Xred ~ log(PE_scaled + 0.001), data = df_sub)
  model_poly   <- lm(Xred ~ PE_scaled + I(PE_scaled^2), data = df_sub)

  # Get annotation
  ann_linear <- get_stats(model_linear, "Linear")
  ann_log    <- get_stats(model_log, "Log")
  ann_poly   <- get_stats(model_poly, "Poly")

  # Plot
  p <- ggplot(df_sub, aes(x = PE_scaled, y = Xred)) +
    geom_point(alpha = 0.6, color = "black") +
    geom_text_repel(aes(label = join_id), size = 2, max.overlaps = 50) +
    stat_smooth(method = "lm", formula = y ~ x, se = FALSE, color = "blue") +
    stat_smooth(method = "lm", formula = y ~ log(x + 0.001), se = FALSE, color = "green", linetype = "dashed") +
    stat_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, color = "red", linetype = "dotdash") +
    annotate("text", x = Inf, y = Inf, label = ann_linear, hjust = 1.05, vjust = 2, color = "blue", size = 4) +
    annotate("text", x = Inf, y = Inf, label = ann_log, hjust = 1.05, vjust = 3.5, color = "green", size = 4) +
    annotate("text", x = Inf, y = Inf, label = ann_poly, hjust = 1.05, vjust = 5, color = "red", size = 4) +
    theme_minimal() +
    labs(title = paste("Regression Models: Xred vs PE (", r, ")"),
         x = "PE (mg/g sample)",
         y = "Xred Fluorescence")

  # Save plot
  filename <- paste0("Xred_PE_regressions_", r, ".png")
  ggsave(filename, plot = p, width = 10, height = 6, dpi = 300)
  plot(p)
}
```

## Function: `analyze_replicates`

üîç analyze_replicates() Function This function processes replicate data for each sample, calculates summary statistics, and optionally selects the best 3 replicates that minimize the coefficient of variation (CV) to reduce the effect of outliers or noisy data.

Key Features: Input: A data frame with replicate observations and associated metadata (e.g., sample weight, join_id, date, etc.).

Output: A summary table with per-sample means, standard deviations, standard errors, CVs, and maximum deviation percentages for each numeric variable.

Optional Filtering: When choose_best_3 = TRUE, the function:

Evaluates all combinations of 3 replicates,

Selects the combination with the lowest CV,

Computes statistics only on those 3 replicates.

Metadata Summary: Also calculates:

The number of replicates per sample,

Average sample weight,

Replication dates,

A list of included/excluded rows (if applicable).

Output File: A wide-format CSV file (e.g., replicate_analysis_summary.csv) containing one row per sample and all summary statistics.

This code chunk runs a function to analyze replicate measurements for each sample in combined_df, selecting the best 3 replicates based on consistency.
It outputs summary statistics with the prefix "E_rep_analy" and updates the main dataframe.
Then, it generates histograms with error bars for key variables (PE_ug_per_g, Xred) to visualize the distribution and variation across samples.

```{r, warning = FALSE}
#combine technical replicates
analyze_replicates(combined_df,
                  id_col = "ID",
                  join_col = "join_id",
                               weight_col = "sample weight",
                               date_col = "date",
                               output_prefix = "all_rep_analy",
                                choose_best_3 = FALSE)

#combine technical replicates choose best three 
analyze_replicates(combined_df,
                  id_col = "ID",
                  join_col = "join_id",
                               weight_col = "sample weight",
                               date_col = "date",
                               output_prefix = "E_rep_analy",
                                choose_best_3 = TRUE)
#Make a bunch of graphs üñ®Ô∏èüñ®Ô∏èüñ®Ô∏è
#final_var <- c("PE_mg_per_gram_sample_mean", "X565_mean", "PE_ug_per_gram_sample_cv", "Xred_mean", "Xred_mean")

graph_histograms_with_error(
  data = combined_df,
  variables = c("PE_mg_per_g_sample", "Xred"),
  id_col = "ID"
)

```

Check effects of enhancement algorithm

```{r}
PErep_enhanced <- read_csv("E_rep_analy_summary.csv") #retrieve analized replicates from enhanced CV 
PErep_all <- read_csv("all_rep_analy_summary.csv") #retrieve analized replicates without enhancement 
#Note, this is a product of analyze_replicates using enhanced replicate selection.
SE_change <- PErep_enhanced$PE_mg_per_g_sample_max_dev_pct -PErep_all$PE_mg_per_g_sample_max_dev_pct
print(SE_change)
SE_change <- SE_change[-51] #remove one NaN at the end
paste("# number of replicates SE acted upon:", length(SE_change[SE_change != 0]))
paste("average improvement by max deviation as a percent of the mean:", abs(mean(SE_change[SE_change != 0], na.rm = TRUE)))
```

```{r}
joindf_by_id(PErep_enhanced, `Sample data`, "PErep_final.csv", key_df1 = "ID", key_df2 = "ID")

graph_replicates_custom_error(
  data = PErep_final,
  id_col = "join_id",
  value_col = "PE_mg_per_g_sample_mean",
  se_col = "PE_mg_per_g_sample_se",
  output_prefix = "E_rep_analy"
)

compare_groups(PErep_final, response_var = "PE_mg_per_g_sample_mean", group_var = "Location") #PE data by location

compare_groups(PErep_final, response_var = "Xred_mean", group_var = "Location") #Fluoresence by location

compare_groups(PErep_final, response_var = "PE_mg_per_g_sample_mean", group_var = "variety") #PE data by variety

compare_groups(PErep_final, response_var = "PE_mg_per_g_sample_mean", group_var = "Life_S") #PE data by life stage

```
